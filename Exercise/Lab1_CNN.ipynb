{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f7c5d-46f3-4cbd-80ad-f1e50cd65096",
   "metadata": {},
   "source": [
    "# Deep Learning Applications: Laboratory #1\n",
    "\n",
    "In this first laboratory we will work relatively simple architectures to get a feel for working with Deep Models. This notebook is designed to work with PyTorch, but as I said in the introductory lecture: please feel free to use and experiment with whatever tools you like.\n",
    "\n",
    "**Important Notes**:\n",
    "1. Be sure to **document** all of your decisions, as well as your intermediate and final results. Make sure your conclusions and analyses are clearly presented. Don't make us dig into your code or walls of printed results to try to draw conclusions from your code.\n",
    "2. If you use code from someone else (e.g. Github, Stack Overflow, ChatGPT, etc) you **must be transparent about it**. Document your sources and explain how you adapted any partial solutions to creat **your** solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed8906-bd19-4b4f-8b79-4feae355ffd6",
   "metadata": {},
   "source": [
    "## Exercise 1: Warming Up\n",
    "In this series of exercises I want you to try to duplicate (on a small scale) the results of the ResNet paper:\n",
    "\n",
    "> [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385), Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR 2016.\n",
    "\n",
    "We will do this in steps using a Multilayer Perceptron on MNIST.\n",
    "\n",
    "Recall that the main message of the ResNet paper is that **deeper** networks do not **guarantee** more reduction in training loss (or in validation accuracy). Below you will incrementally build a sequence of experiments to verify this for an MLP. A few guidelines:\n",
    "\n",
    "+ I have provided some **starter** code at the beginning. **NONE** of this code should survive in your solutions. Not only is it **very** badly written, it is also written in my functional style that also obfuscates what it's doing (in part to **discourage** your reuse!). It's just to get you *started*.\n",
    "+ These exercises ask you to compare **multiple** training runs, so it is **really** important that you factor this into your **pipeline**. Using [Tensorboard](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html) is a **very** good idea -- or, even better [Weights and Biases](https://wandb.ai/site).\n",
    "+ You may work and submit your solutions in **groups of at most two**. Share your ideas with everyone, but the solutions you submit *must be your own*.\n",
    "\n",
    "First some boilerplate to get you started, then on to the actual exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2b6d1-3df0-464c-9a5f-8c611257a971",
   "metadata": {},
   "source": [
    "### Preface: Some code to get you started\n",
    "\n",
    "What follows is some **very simple** code for training an MLP on MNIST. The point of this code is to get you up and running (and to verify that your Python environment has all needed dependencies).\n",
    "\n",
    "**Note**: As you read through my code and execute it, this would be a good time to think about *abstracting* **your** model definition, and training and evaluation pipelines in order to make it easier to compare performance of different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b98e27",
   "metadata": {},
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3a8282-2322-4dca-b76e-2f3863bc75fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Import PyTorch and Torchvion\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f821098",
   "metadata": {},
   "source": [
    "\n",
    "### ***Further settings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555086a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1abf7d83e30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "torch.manual_seed(808)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875008c3-306c-4e39-a845-d7bda7862621",
   "metadata": {},
   "source": [
    "#### A basic, parameterized MLP\n",
    "\n",
    "This is a very basic implementation of a Multilayer Perceptron. Don't waste too much time trying to figure out how it works -- the important detail is that it allows you to pass in a list of input, hidden layer, and output *widths*. **Your** implementation should also support this for the exercises to come."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cad13-ee2c-4e43-b5c7-31760da8c2df",
   "metadata": {},
   "source": [
    "# *Exercise 1.1: A baseline MLP*\n",
    "\n",
    "Implement a *simple* Multilayer Perceptron to classify the 10 digits of MNIST (e.g. two *narrow* layers). Use my code above as inspiration, but implement your own training pipeline -- you will need it later. Train this model to convergence, monitoring (at least) the loss and accuracy on the training and validation sets for every epoch. Below I include a basic implementation to get you started -- remember that you should write your *own* pipeline!\n",
    "\n",
    "**Note**: This would be a good time to think about *abstracting* your model definition, and training and evaluation pipelines in order to make it easier to compare performance of different models.\n",
    "\n",
    "**Important**: Given the *many* runs you will need to do, and the need to *compare* performance between them, this would **also** be a great point to study how **Tensorboard** or **Weights and Biases** can be used for performance monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb421a",
   "metadata": {},
   "source": [
    "###  **Model architecure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce58203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "         # Dropout 20%\n",
    "        self.dropout = nn.Dropout(p=0.2)  \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)          \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)          \n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a67f6",
   "metadata": {},
   "source": [
    "### **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bac6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 128\n",
    "val_fraction=0.1\n",
    "\n",
    "# Load the MNIST dataset with standard normalization, and split the training set into training and validation subsets\n",
    "def load_mnist_datasets(data_dir='./data', val_fraction=val_fraction, download=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    full_dataset = MNIST(root=data_dir, train=True, download=download, transform=transform)\n",
    "    test = MNIST(root=data_dir, train=False, download=download, transform=transform)\n",
    "\n",
    "    total_train = len(full_dataset)\n",
    "    val_size = int(total_train * val_fraction)\n",
    "    train_size = total_train - val_size\n",
    "\n",
    "    train, val = torch.utils.data.random_split(full_dataset, [train_size, val_size]) \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "train_loader, val_loader, test_loader = load_mnist_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44222001",
   "metadata": {},
   "source": [
    "### **Traning configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca369d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device,\n",
    "                patience=5, min_delta=0.001,\n",
    "                delta_overfit=0.01, overfit_patience=2,\n",
    "                wandb_project=None, wandb_run_name=None):\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    overfit_epochs = 0\n",
    "    insufficient_change_epochs = 0\n",
    "    prev_val_loss = None\n",
    "\n",
    "    # Inizializza wandb una sola volta all'inizio del training (se richiesto)\n",
    "    if wandb_project is not None:\n",
    "        wandb.init(project=wandb_project, name=wandb_run_name, reinit=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_acc = 0, 0\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "            val_loss /= val_total\n",
    "            val_acc = val_correct / val_total\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train_Loss: {train_loss:.4f} | Train_Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val_Loss: {val_loss:.4f} | Val_Acc: {val_acc:.4f}\\n\")\n",
    "\n",
    "        # Log su wandb\n",
    "        if wandb_project is not None:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc\n",
    "            })\n",
    "\n",
    "        # Early stopping e controllo overfitting\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            overfit_epochs = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            if val_loss > best_val_loss + delta_overfit:\n",
    "                overfit_epochs += 1\n",
    "                print(f\"  Warning: val_loss > best_val_loss + delta_overfit = {best_val_loss + delta_overfit:.4f}\")\n",
    "                if overfit_epochs >= overfit_patience:\n",
    "                    print(f\"Early stopping due to overfitting\\nEpoch {epoch+1}: val_loss has been higher than best_val_loss + delta ({delta_overfit}) for {overfit_patience} epochs.\")\n",
    "                    break\n",
    "            else:\n",
    "                overfit_epochs = 0\n",
    "\n",
    "        if prev_val_loss is None:\n",
    "            prev_val_loss = val_loss\n",
    "            continue\n",
    "\n",
    "        delta = abs(prev_val_loss - val_loss)\n",
    "        if delta >= min_delta:\n",
    "            insufficient_change_epochs = 0\n",
    "        else:\n",
    "            insufficient_change_epochs += 1\n",
    "            print(f\"  Δ(val_loss) < {min_delta} for {insufficient_change_epochs} consecutive epoch(s)\")\n",
    "            if insufficient_change_epochs >= patience:\n",
    "                print(f\"Early stopping due to stagnation\\nEpoch {epoch+1}: No significant change (|Δ| < {min_delta}) for {patience} consecutive epochs.\")\n",
    "                break\n",
    "\n",
    "        prev_val_loss = val_loss\n",
    "\n",
    "    # Chiudi wandb alla fine\n",
    "    if wandb_project is not None:\n",
    "        wandb.finish()\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e9010",
   "metadata": {},
   "source": [
    "### **Evaluation configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab95338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')  # weighted per multilabel bilanciato\n",
    "    \n",
    "\n",
    "    return avg_loss, accuracy, precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4512abe",
   "metadata": {},
   "source": [
    "## ***Model Traning*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1625bc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>train_acc</td><td>0.9805</td></tr><tr><td>train_loss</td><td>0.06028</td></tr><tr><td>val_acc</td><td>0.97883</td></tr><tr><td>val_loss</td><td>0.07217</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2lp_run</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/MLP/runs/52qb7ygv' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/MLP/runs/52qb7ygv</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/MLP' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/MLP</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250803_132645-52qb7ygv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (3.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250803_132952-5qdknlzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/AML_Lab1/runs/5qdknlzc' target=\"_blank\">2lp_run</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/AML_Lab1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/AML_Lab1' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_Lab1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/AML_Lab1/runs/5qdknlzc' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_Lab1/runs/5qdknlzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  Train_Loss: 0.4294 | Train_Acc: 0.8712\n",
      "  Val_Loss: 0.1747 | Val_Acc: 0.9437\n",
      "\n",
      "Epoch 2/50\n",
      "  Train_Loss: 0.1928 | Train_Acc: 0.9423\n",
      "  Val_Loss: 0.1244 | Val_Acc: 0.9607\n",
      "\n",
      "Epoch 3/50\n",
      "  Train_Loss: 0.1461 | Train_Acc: 0.9565\n",
      "  Val_Loss: 0.1018 | Val_Acc: 0.9695\n",
      "\n",
      "Epoch 4/50\n",
      "  Train_Loss: 0.1227 | Train_Acc: 0.9635\n",
      "  Val_Loss: 0.0962 | Val_Acc: 0.9708\n",
      "\n",
      "Epoch 5/50\n",
      "  Train_Loss: 0.1068 | Train_Acc: 0.9667\n",
      "  Val_Loss: 0.0876 | Val_Acc: 0.9737\n",
      "\n",
      "Epoch 6/50\n",
      "  Train_Loss: 0.0962 | Train_Acc: 0.9698\n",
      "  Val_Loss: 0.0851 | Val_Acc: 0.9737\n",
      "\n",
      "Epoch 7/50\n",
      "  Train_Loss: 0.0869 | Train_Acc: 0.9731\n",
      "  Val_Loss: 0.0783 | Val_Acc: 0.9767\n",
      "\n",
      "Epoch 8/50\n",
      "  Train_Loss: 0.0793 | Train_Acc: 0.9757\n",
      "  Val_Loss: 0.0794 | Val_Acc: 0.9755\n",
      "\n",
      "Epoch 9/50\n",
      "  Train_Loss: 0.0742 | Train_Acc: 0.9764\n",
      "  Val_Loss: 0.0793 | Val_Acc: 0.9775\n",
      "\n",
      "  Δ(val_loss) < 0.001 for 1 consecutive epoch(s)\n",
      "Epoch 10/50\n",
      "  Train_Loss: 0.0710 | Train_Acc: 0.9783\n",
      "  Val_Loss: 0.0773 | Val_Acc: 0.9762\n",
      "\n",
      "Epoch 11/50\n",
      "  Train_Loss: 0.0662 | Train_Acc: 0.9790\n",
      "  Val_Loss: 0.0849 | Val_Acc: 0.9758\n",
      "\n",
      "Epoch 12/50\n",
      "  Train_Loss: 0.0614 | Train_Acc: 0.9798\n",
      "  Val_Loss: 0.0789 | Val_Acc: 0.9755\n",
      "\n",
      "Epoch 13/50\n",
      "  Train_Loss: 0.0579 | Train_Acc: 0.9814\n",
      "  Val_Loss: 0.0786 | Val_Acc: 0.9760\n",
      "\n",
      "  Δ(val_loss) < 0.001 for 1 consecutive epoch(s)\n",
      "Epoch 14/50\n",
      "  Train_Loss: 0.0576 | Train_Acc: 0.9819\n",
      "  Val_Loss: 0.0781 | Val_Acc: 0.9770\n",
      "\n",
      "  Δ(val_loss) < 0.001 for 2 consecutive epoch(s)\n",
      "Epoch 15/50\n",
      "  Train_Loss: 0.0543 | Train_Acc: 0.9820\n",
      "  Val_Loss: 0.0786 | Val_Acc: 0.9770\n",
      "\n",
      "  Δ(val_loss) < 0.001 for 3 consecutive epoch(s)\n",
      "Epoch 16/50\n",
      "  Train_Loss: 0.0515 | Train_Acc: 0.9827\n",
      "  Val_Loss: 0.0786 | Val_Acc: 0.9780\n",
      "\n",
      "  Δ(val_loss) < 0.001 for 4 consecutive epoch(s)\n",
      "Epoch 17/50\n",
      "  Train_Loss: 0.0495 | Train_Acc: 0.9835\n",
      "  Val_Loss: 0.0773 | Val_Acc: 0.9773\n",
      "\n",
      "Epoch 18/50\n",
      "  Train_Loss: 0.0509 | Train_Acc: 0.9829\n",
      "  Val_Loss: 0.0728 | Val_Acc: 0.9793\n",
      "\n",
      "Epoch 19/50\n",
      "  Train_Loss: 0.0493 | Train_Acc: 0.9845\n",
      "  Val_Loss: 0.0718 | Val_Acc: 0.9777\n",
      "\n",
      "  Δ(val_loss) < 0.001 for 1 consecutive epoch(s)\n",
      "Epoch 20/50\n",
      "  Train_Loss: 0.0456 | Train_Acc: 0.9852\n",
      "  Val_Loss: 0.0837 | Val_Acc: 0.9768\n",
      "\n",
      "  Warning: val_loss > best_val_loss + delta_overfit = 0.0818\n",
      "Epoch 21/50\n",
      "  Train_Loss: 0.0445 | Train_Acc: 0.9852\n",
      "  Val_Loss: 0.0835 | Val_Acc: 0.9770\n",
      "\n",
      "  Warning: val_loss > best_val_loss + delta_overfit = 0.0818\n",
      "Early stopping due to overfitting\n",
      "Epoch 21: val_loss has been higher than best_val_loss + delta (0.01) for 2 epochs.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇████████████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▇▇▇█▇▇▇▇████████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>21</td></tr><tr><td>train_acc</td><td>0.98517</td></tr><tr><td>train_loss</td><td>0.04445</td></tr><tr><td>val_acc</td><td>0.977</td></tr><tr><td>val_loss</td><td>0.08347</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2lp_run</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/AML_Lab1/runs/5qdknlzc' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_Lab1/runs/5qdknlzc</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/AML_Lab1' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_Lab1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250803_132952-5qdknlzc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "model = MLP(input_size=28*28, hidden_size=128, output_size=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device,wandb_project=\"AML_Lab1\",\n",
    "    wandb_run_name=\"2lp_run\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4090f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0778 | Test Accuracy: 0.9796 | Test Precision: 0.9797\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss, test_acc, precision = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f} | Test Precision: {precision:.4f}\")\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8ad9b-e3ae-4c49-9bec-35aaea149b08",
   "metadata": {},
   "source": [
    "# *Exercise 1.2: Adding Residual Connections*\n",
    "\n",
    "Implement a variant of your parameterized MLP network to support **residual** connections. Your network should be defined as a composition of **residual MLP** blocks that have one or more linear layers and add a skip connection from the block input to the output of the final linear layer.\n",
    "\n",
    "**Compare** the performance (in training/validation loss and test accuracy) of your MLP and ResidualMLP for a range of depths. Verify that deeper networks **with** residual connections are easier to train than a network of the same depth **without** residual connections.\n",
    "\n",
    "**For extra style points**: See if you can explain by analyzing the gradient magnitudes on a single training batch *why* this is the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099bda56",
   "metadata": {},
   "source": [
    "###  **Model architecure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bcff82-756a-4ffa-92ae-a939fa21f5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualMLPBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(dim, dim)\n",
    "        self.linear2 = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)      \n",
    "        out = F.relu(out)          \n",
    "        out = self.linear2(out)  \n",
    "        return x + out   \n",
    "    \n",
    "    \n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, depth):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.blocks = nn.Sequential(*[ResidualMLPBlock(hidden_dim) for _ in range(depth)])\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60669a",
   "metadata": {},
   "source": [
    "## ***Model trainig***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d218671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResidualMLP(input_size=28*28, middle_size=128, hidden_size=64, output_size=10, depth=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59bdd8-3377-4311-b45f-511c2fb0b53e",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Rinse and Repeat (but with a CNN)\n",
    "\n",
    "Repeat the verification you did above, but with **Convolutional** Neural Networks. If you were careful about abstracting your model and training code, this should be a simple exercise. Show that **deeper** CNNs *without* residual connections do not always work better and **even deeper** ones *with* residual connections.\n",
    "\n",
    "**Hint**: You probably should do this exercise using CIFAR-10, since MNIST is *very* easy (at least up to about 99% accuracy).\n",
    "\n",
    "**Tip**: Feel free to reuse the ResNet building blocks defined in `torchvision.models.resnet` (e.g. [BasicBlock](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L59) which handles the cascade of 3x3 convolutions, skip connections, and optional downsampling). This is an excellent exercise in code diving. \n",
    "\n",
    "**Spoiler**: Depending on the optional exercises you plan to do below, you should think *very* carefully about the architectures of your CNNs here (so you can reuse them!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8baa0e-b17f-4a77-8a88-dadfdc6763ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4de2f2-abc5-4f98-9eaf-3497f734a022",
   "metadata": {},
   "source": [
    "-----\n",
    "## Exercise 2: Choose at Least One\n",
    "\n",
    "Below are **three** exercises that ask you to deepen your understanding of Deep Networks for visual recognition. You must choose **at least one** of the below for your final submission -- feel free to do **more**, but at least **ONE** you must submit. Each exercise is designed to require you to dig your hands **deep** into the guts of your models in order to do new and interesting things.\n",
    "\n",
    "**Note**: These exercises are designed to use your small, custom CNNs and small datasets. This is to keep training times reasonable. If you have a decent GPU, feel free to use pretrained ResNets and larger datasets (e.g. the [Imagenette](https://pytorch.org/vision/0.20/generated/torchvision.datasets.Imagenette.html#torchvision.datasets.Imagenette) dataset at 160px)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07978e8e-9f2e-4949-9699-495af6cb6349",
   "metadata": {},
   "source": [
    "### Exercise 2.1: *Fine-tune* a pre-trained model\n",
    "Train one of your residual CNN models from Exercise 1.3 on CIFAR-10. Then:\n",
    "1. Use the pre-trained model as a **feature extractor** (i.e. to extract the feature activations of the layer input into the classifier) on CIFAR-100. Use a **classical** approach (e.g. Linear SVM, K-Nearest Neighbor, or Bayesian Generative Classifier) from scikit-learn to establish a **stable baseline** performance on CIFAR-100 using the features extracted using your CNN.\n",
    "2. Fine-tune your CNN on the CIFAR-100 training set and compare with your stable baseline. Experiment with different strategies:\n",
    "    - Unfreeze some of the earlier layers for fine-tuning.\n",
    "    - Test different optimizers (Adam, SGD, etc.).\n",
    "\n",
    "Each of these steps will require you to modify your model definition in some way. For 1, you will need to return the activations of the last fully-connected layer (or the global average pooling layer). For 2, you will need to replace the original, 10-class classifier with a new, randomly-initialized 100-class classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e81a3-08ca-4549-a2f8-f47cf5a0308b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a3a7b-2ed6-4f58-a1b7-5ab1fc432893",
   "metadata": {},
   "source": [
    "### Exercise 2.2: *Distill* the knowledge from a large model into a smaller one\n",
    "In this exercise you will see if you can derive a *small* model that performs comparably to a larger one on CIFAR-10. To do this, you will use [Knowledge Distillation](https://arxiv.org/abs/1503.02531):\n",
    "\n",
    "> Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the Knowledge in a Neural Network, NeurIPS 2015.\n",
    "\n",
    "To do this:\n",
    "1. Train one of your best-performing CNNs on CIFAR-10 from Exercise 1.3 above. This will be your **teacher** model.\n",
    "2. Define a *smaller* variant with about half the number of parameters (change the width and/or depth of the network). Train it on CIFAR-10 and verify that it performs *worse* than your **teacher**. This small network will be your **student** model.\n",
    "3. Train the **student** using a combination of **hard labels** from the CIFAR-10 training set (cross entropy loss) and **soft labels** from predictions of the **teacher** (Kulback-Leibler loss between teacher and student).\n",
    "\n",
    "Try to optimize training parameters in order to maximize the performance of the student. It should at least outperform the student trained only on hard labels in Setp 2.\n",
    "\n",
    "**Tip**: You can save the predictions of the trained teacher network on the training set and adapt your dataloader to provide them together with hard labels. This will **greatly** speed up training compared to performing a forward pass through the teacher for each batch of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33c912-0716-44ef-a91b-47ca19a2b2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243f811-8227-4c6f-b07f-56e8cd91643a",
   "metadata": {},
   "source": [
    "### Exercise 2.3: *Explain* the predictions of a CNN\n",
    "\n",
    "Use the CNN model you trained in Exercise 1.3 and implement [*Class Activation Maps*](http://cnnlocalization.csail.mit.edu/#:~:text=A%20class%20activation%20map%20for,decision%20made%20by%20the%20CNN.):\n",
    "\n",
    "> B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization. CVPR'16 (arXiv:1512.04150, 2015).\n",
    "\n",
    "Use your CNN implementation to demonstrate how your trained CNN *attends* to specific image features to recognize *specific* classes. Try your implementation out using a pre-trained ResNet-18 model and some images from the [Imagenette](https://pytorch.org/vision/0.20/generated/torchvision.datasets.Imagenette.html#torchvision.datasets.Imagenette) dataset -- I suggest you start with the low resolution version of images at 160px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634a700-56c2-48fd-96e0-4c94d1bd0cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
