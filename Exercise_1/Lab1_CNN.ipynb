{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f7c5d-46f3-4cbd-80ad-f1e50cd65096",
   "metadata": {},
   "source": [
    "# Deep Learning Applications: Laboratory #1\n",
    "\n",
    "In this first laboratory we will work relatively simple architectures to get a feel for working with Deep Models. This notebook is designed to work with PyTorch, but as I said in the introductory lecture: please feel free to use and experiment with whatever tools you like.\n",
    "\n",
    "**Important Notes**:\n",
    "1. Be sure to **document** all of your decisions, as well as your intermediate and final results. Make sure your conclusions and analyses are clearly presented. Don't make us dig into your code or walls of printed results to try to draw conclusions from your code.\n",
    "2. If you use code from someone else (e.g. Github, Stack Overflow, ChatGPT, etc) you **must be transparent about it**. Document your sources and explain how you adapted any partial solutions to creat **your** solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed8906-bd19-4b4f-8b79-4feae355ffd6",
   "metadata": {},
   "source": [
    "## Exercise 1: Warming Up\n",
    "In this series of exercises I want you to try to duplicate (on a small scale) the results of the ResNet paper:\n",
    "\n",
    "> [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385), Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR 2016.\n",
    "\n",
    "We will do this in steps using a Multilayer Perceptron on MNIST.\n",
    "\n",
    "Recall that the main message of the ResNet paper is that **deeper** networks do not **guarantee** more reduction in training loss (or in validation accuracy). Below you will incrementally build a sequence of experiments to verify this for an MLP. A few guidelines:\n",
    "\n",
    "+ I have provided some **starter** code at the beginning. **NONE** of this code should survive in your solutions. Not only is it **very** badly written, it is also written in my functional style that also obfuscates what it's doing (in part to **discourage** your reuse!). It's just to get you *started*.\n",
    "+ These exercises ask you to compare **multiple** training runs, so it is **really** important that you factor this into your **pipeline**. Using [Tensorboard](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html) is a **very** good idea -- or, even better [Weights and Biases](https://wandb.ai/site).\n",
    "+ You may work and submit your solutions in **groups of at most two**. Share your ideas with everyone, but the solutions you submit *must be your own*.\n",
    "\n",
    "First some boilerplate to get you started, then on to the actual exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2b6d1-3df0-464c-9a5f-8c611257a971",
   "metadata": {},
   "source": [
    "### Preface: Some code to get you started\n",
    "\n",
    "What follows is some **very simple** code for training an MLP on MNIST. The point of this code is to get you up and running (and to verify that your Python environment has all needed dependencies).\n",
    "\n",
    "**Note**: As you read through my code and execute it, this would be a good time to think about *abstracting* **your** model definition, and training and evaluation pipelines in order to make it easier to compare performance of different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b98e27",
   "metadata": {},
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3a8282-2322-4dca-b76e-2f3863bc75fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import PyTorch and Torchvion\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "#import Datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f821098",
   "metadata": {},
   "source": [
    "\n",
    "### ***Further settings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555086a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a328dca550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "torch.manual_seed(808)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875008c3-306c-4e39-a845-d7bda7862621",
   "metadata": {},
   "source": [
    "#### A basic, parameterized MLP\n",
    "\n",
    "This is a very basic implementation of a Multilayer Perceptron. Don't waste too much time trying to figure out how it works -- the important detail is that it allows you to pass in a list of input, hidden layer, and output *widths*. **Your** implementation should also support this for the exercises to come."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cad13-ee2c-4e43-b5c7-31760da8c2df",
   "metadata": {},
   "source": [
    "# *Exercise 1.1: A baseline MLP*\n",
    "\n",
    "Implement a *simple* Multilayer Perceptron to classify the 10 digits of MNIST (e.g. two *narrow* layers). Use my code above as inspiration, but implement your own training pipeline -- you will need it later. Train this model to convergence, monitoring (at least) the loss and accuracy on the training and validation sets for every epoch. Below I include a basic implementation to get you started -- remember that you should write your *own* pipeline!\n",
    "\n",
    "**Note**: This would be a good time to think about *abstracting* your model definition, and training and evaluation pipelines in order to make it easier to compare performance of different models.\n",
    "\n",
    "**Important**: Given the *many* runs you will need to do, and the need to *compare* performance between them, this would **also** be a great point to study how **Tensorboard** or **Weights and Biases** can be used for performance monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb421a",
   "metadata": {},
   "source": [
    "###  **Model architecure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce58203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with 2 hidden layer \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1,hidden_size2, output_size,dropout_rate):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  \n",
    "        self.out = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)          \n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a67f6",
   "metadata": {},
   "source": [
    "### **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bac6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data parameters\n",
    "batch_size = 128\n",
    "val_fraction=0.1\n",
    "\n",
    "# Load the MNIST dataset with standard normalization, and split the training set into training and validation subsets\n",
    "def load_mnist_datasets(data_dir='./data', val_fraction=val_fraction, download=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    full_dataset = MNIST(root=data_dir, train=True, download=download, transform=transform)\n",
    "    test = MNIST(root=data_dir, train=False, download=download, transform=transform)\n",
    "\n",
    "    total_train = len(full_dataset)\n",
    "    val_size = int(total_train * val_fraction)\n",
    "    train_size = total_train - val_size\n",
    "\n",
    "    train, val = torch.utils.data.random_split(full_dataset, [train_size, val_size]) \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "train_loader, val_loader, test_loader = load_mnist_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44222001",
   "metadata": {},
   "source": [
    "## **TRANING CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca369d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device,\n",
    "                patience, min_delta,\n",
    "                delta_overfit, overfit_patience,\n",
    "                wandb_project=None, wandb_run_name=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    overfit_epochs = 0\n",
    "    insufficient_change_epochs = 0\n",
    "    prev_val_loss = None\n",
    "    actual_epochs = num_epochs  # Default: all epochs completed\n",
    "\n",
    "    # Initialize Weights & Biases\n",
    "    if wandb_project is not None:\n",
    "        wandb.init(project=wandb_project, name=wandb_run_name, reinit=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss, val_acc = 0, 0\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "            val_loss /= val_total\n",
    "            val_acc = val_correct / val_total\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        # Print training progress\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train_Loss: {train_loss:.4f} | Train_Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val_Loss: {val_loss:.4f} | Val_Acc: {val_acc:.4f}\\n\")\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        if wandb_project is not None:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc\n",
    "            })\n",
    "\n",
    "        # Save best model and reset overfitting counter\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            overfit_epochs = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            # If validation loss increases, count as potential overfitting\n",
    "            if val_loss > best_val_loss + delta_overfit:\n",
    "                overfit_epochs += 1\n",
    "                print(f\"⚠️WARNING:Change in the trend of value  val_loss: best value= {best_val_loss:.4f} | current value= {val_loss:.4f}\")\n",
    "                if overfit_epochs >= overfit_patience: \n",
    "                    print(f\"🛑Early stopping due to high risk of OVERFITTING\\nEpoch {epoch+1}: val_loss is INCREASING for {overfit_patience} epochs\")\n",
    "                    actual_epochs = epoch + 1\n",
    "                    break\n",
    "            else:\n",
    "                overfit_epochs = 0\n",
    "\n",
    "        # Check for stagnation\n",
    "        if prev_val_loss is None:\n",
    "            prev_val_loss = val_loss\n",
    "            continue\n",
    "\n",
    "        delta = abs(prev_val_loss - val_loss)\n",
    "        if delta >= min_delta:\n",
    "            insufficient_change_epochs = 0\n",
    "        else:\n",
    "            insufficient_change_epochs += 1\n",
    "            print(f\"⚠️Δ(val_loss) < {min_delta} for {insufficient_change_epochs} consecutive epoch(s)\")\n",
    "            if insufficient_change_epochs >= patience:\n",
    "                print(f\"🛑Early stopping due to STAGNATION\\nEpoch {epoch+1}: No significant change (|Δ| < {min_delta}) for {patience} consecutive epochs.\")\n",
    "                actual_epochs = epoch + 1\n",
    "                break\n",
    "\n",
    "        prev_val_loss = val_loss\n",
    "\n",
    "    if wandb_project is not None:\n",
    "        wandb.finish()\n",
    "\n",
    "    return train_losses, val_losses, actual_epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e9010",
   "metadata": {},
   "source": [
    "### **Evaluation configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab95338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return avg_loss, accuracy, precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4512abe",
   "metadata": {},
   "source": [
    "## ***Model Traning*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1625bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: emile-agbedanu (emile-agbedanu-none) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_144059-yd0svuzk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/AML_MLP/runs/yd0svuzk' target=\"_blank\">2lp_run</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/AML_MLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/AML_MLP' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_MLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/AML_MLP/runs/yd0svuzk' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_MLP/runs/yd0svuzk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  Train_Loss: 0.3937 | Train_Acc: 0.8839\n",
      "  Val_Loss: 0.1732 | Val_Acc: 0.9472\n",
      "\n",
      "Epoch 2/50\n",
      "  Train_Loss: 0.1674 | Train_Acc: 0.9504\n",
      "  Val_Loss: 0.1312 | Val_Acc: 0.9577\n",
      "\n",
      "Epoch 3/50\n",
      "  Train_Loss: 0.1196 | Train_Acc: 0.9635\n",
      "  Val_Loss: 0.1022 | Val_Acc: 0.9680\n",
      "\n",
      "Epoch 4/50\n",
      "  Train_Loss: 0.0929 | Train_Acc: 0.9717\n",
      "  Val_Loss: 0.0968 | Val_Acc: 0.9708\n",
      "\n",
      "Epoch 5/50\n",
      "  Train_Loss: 0.0763 | Train_Acc: 0.9764\n",
      "  Val_Loss: 0.0909 | Val_Acc: 0.9720\n",
      "\n",
      "Epoch 6/50\n",
      "  Train_Loss: 0.0646 | Train_Acc: 0.9792\n",
      "  Val_Loss: 0.0852 | Val_Acc: 0.9713\n",
      "\n",
      "Epoch 7/50\n",
      "  Train_Loss: 0.0564 | Train_Acc: 0.9822\n",
      "  Val_Loss: 0.0768 | Val_Acc: 0.9777\n",
      "\n",
      "Epoch 8/50\n",
      "  Train_Loss: 0.0470 | Train_Acc: 0.9852\n",
      "  Val_Loss: 0.0828 | Val_Acc: 0.9740\n",
      "\n",
      "Epoch 9/50\n",
      "  Train_Loss: 0.0422 | Train_Acc: 0.9856\n",
      "  Val_Loss: 0.0785 | Val_Acc: 0.9743\n",
      "\n",
      "Epoch 10/50\n",
      "  Train_Loss: 0.0366 | Train_Acc: 0.9878\n",
      "  Val_Loss: 0.0838 | Val_Acc: 0.9767\n",
      "\n",
      "Epoch 11/50\n",
      "  Train_Loss: 0.0334 | Train_Acc: 0.9890\n",
      "  Val_Loss: 0.0824 | Val_Acc: 0.9762\n",
      "\n",
      "Epoch 12/50\n",
      "  Train_Loss: 0.0294 | Train_Acc: 0.9899\n",
      "  Val_Loss: 0.0809 | Val_Acc: 0.9775\n",
      "\n",
      "Epoch 13/50\n",
      "  Train_Loss: 0.0272 | Train_Acc: 0.9906\n",
      "  Val_Loss: 0.0915 | Val_Acc: 0.9785\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0768 | current value= 0.0915\n",
      "Epoch 14/50\n",
      "  Train_Loss: 0.0254 | Train_Acc: 0.9912\n",
      "  Val_Loss: 0.0891 | Val_Acc: 0.9788\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0768 | current value= 0.0891\n",
      "Epoch 15/50\n",
      "  Train_Loss: 0.0213 | Train_Acc: 0.9927\n",
      "  Val_Loss: 0.0900 | Val_Acc: 0.9773\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0768 | current value= 0.0900\n",
      "⚠️Δ(val_loss) < 0.001 for 1 consecutive epoch(s)\n",
      "Epoch 16/50\n",
      "  Train_Loss: 0.0219 | Train_Acc: 0.9927\n",
      "  Val_Loss: 0.0927 | Val_Acc: 0.9785\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0768 | current value= 0.0927\n",
      "Epoch 17/50\n",
      "  Train_Loss: 0.0205 | Train_Acc: 0.9926\n",
      "  Val_Loss: 0.1058 | Val_Acc: 0.9753\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0768 | current value= 0.1058\n",
      "🛑Early stopping due to high risk of OVERFITTING\n",
      "Epoch 17: val_loss is INCREASING for 5 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▆▆▆▆█▇▇█▇█████▇</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▂▁▁▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>17</td></tr><tr><td>train_acc</td><td>0.99265</td></tr><tr><td>train_loss</td><td>0.02053</td></tr><tr><td>val_acc</td><td>0.97533</td></tr><tr><td>val_loss</td><td>0.10577</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2lp_run</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/AML_MLP/runs/yd0svuzk' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_MLP/runs/yd0svuzk</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/AML_MLP' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_MLP</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_144059-yd0svuzk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters of a standard MLP\n",
    "input_size = 28 * 28\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "output_size = 10\n",
    "dropout_rate = 0.2\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Parameters for early stopping and overfitting detection\n",
    "patience = 5\n",
    "min_delta = 0.001\n",
    "delta_overfit = 0.01\n",
    "overfit_patience = 5\n",
    "\n",
    "# WandB configuration\n",
    "wandb_project = None\n",
    "wandb_run_name = None\n",
    "\n",
    "# Creation and traning of MLP\n",
    "mlp_model = MLP(input_size, hidden_size1, hidden_size2, output_size, dropout_rate)\n",
    "mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, val_losses, mlp_epoch = train_model(\n",
    "    mlp_model, train_loader, val_loader, mlp_optimizer, criterion, num_epochs, device,\n",
    "    patience, min_delta, delta_overfit, overfit_patience,\n",
    "    wandb_project=\"AML_MLP\", wandb_run_name=\"2lp_run\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac16cc1",
   "metadata": {},
   "source": [
    "### **Model Evalation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4090f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test Loss: 0.1053 | Test Accuracy: 0.9739 | Test Precision: 0.9743\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on test set\n",
    "mlp_test_loss, mlp_test_acc, mlp_precision = evaluate(mlp_model, test_loader, criterion, device)\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(f\"Test Loss: {mlp_test_loss:.4f} | Test Accuracy: {mlp_test_acc:.4f} | Test Precision: {mlp_precision:.4f}\")\n",
    "print(f\"{'-'*80}\\n\")\n",
    "\n",
    "# Plot learning curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8ad9b-e3ae-4c49-9bec-35aaea149b08",
   "metadata": {},
   "source": [
    "# *Exercise 1.2: Adding Residual Connections*\n",
    "\n",
    "Implement a variant of your parameterized MLP network to support **residual** connections. Your network should be defined as a composition of **residual MLP** blocks that have one or more linear layers and add a skip connection from the block input to the output of the final linear layer.\n",
    "\n",
    "**Compare** the performance (in training/validation loss and test accuracy) of your MLP and ResidualMLP for a range of depths. Verify that deeper networks **with** residual connections are easier to train than a network of the same depth **without** residual connections.\n",
    "\n",
    "**For extra style points**: See if you can explain by analyzing the gradient magnitudes on a single training batch *why* this is the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099bda56",
   "metadata": {},
   "source": [
    "###  **Model architecure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90bcff82-756a-4ffa-92ae-a939fa21f5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, input_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# Residual MLP with stacked residual blocks\n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_blocks, dropout_rate):\n",
    "        super(ResidualMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ResidualBlock(hidden_size, hidden_size, dropout_rate) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.fc1.in_features) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.blocks(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529aea2",
   "metadata": {},
   "source": [
    "###    **ResMLP traning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ac2ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: emile-agbedanu (emile-agbedanu-none) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_195003-2a1f40jc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/AML_ResMLP/runs/2a1f40jc' target=\"_blank\">ResidualMLP</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/AML_ResMLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/AML_ResMLP' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_ResMLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/AML_ResMLP/runs/2a1f40jc' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_ResMLP/runs/2a1f40jc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  Train_Loss: 0.2812 | Train_Acc: 0.9159\n",
      "  Val_Loss: 0.1367 | Val_Acc: 0.9565\n",
      "\n",
      "Epoch 2/50\n",
      "  Train_Loss: 0.1149 | Train_Acc: 0.9644\n",
      "  Val_Loss: 0.1185 | Val_Acc: 0.9632\n",
      "\n",
      "Epoch 3/50\n",
      "  Train_Loss: 0.0828 | Train_Acc: 0.9745\n",
      "  Val_Loss: 0.0866 | Val_Acc: 0.9722\n",
      "\n",
      "Epoch 4/50\n",
      "  Train_Loss: 0.0635 | Train_Acc: 0.9800\n",
      "  Val_Loss: 0.0828 | Val_Acc: 0.9750\n",
      "\n",
      "Epoch 5/50\n",
      "  Train_Loss: 0.0524 | Train_Acc: 0.9829\n",
      "  Val_Loss: 0.0879 | Val_Acc: 0.9730\n",
      "\n",
      "Epoch 6/50\n",
      "  Train_Loss: 0.0421 | Train_Acc: 0.9864\n",
      "  Val_Loss: 0.0911 | Val_Acc: 0.9770\n",
      "\n",
      "Epoch 7/50\n",
      "  Train_Loss: 0.0396 | Train_Acc: 0.9875\n",
      "  Val_Loss: 0.0750 | Val_Acc: 0.9783\n",
      "\n",
      "Epoch 8/50\n",
      "  Train_Loss: 0.0298 | Train_Acc: 0.9905\n",
      "  Val_Loss: 0.0878 | Val_Acc: 0.9758\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0750 | current value= 0.0878\n",
      "Epoch 9/50\n",
      "  Train_Loss: 0.0270 | Train_Acc: 0.9909\n",
      "  Val_Loss: 0.0784 | Val_Acc: 0.9773\n",
      "\n",
      "Epoch 10/50\n",
      "  Train_Loss: 0.0275 | Train_Acc: 0.9909\n",
      "  Val_Loss: 0.0867 | Val_Acc: 0.9760\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0750 | current value= 0.0867\n",
      "Epoch 11/50\n",
      "  Train_Loss: 0.0216 | Train_Acc: 0.9928\n",
      "  Val_Loss: 0.0919 | Val_Acc: 0.9777\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0750 | current value= 0.0919\n",
      "Epoch 12/50\n",
      "  Train_Loss: 0.0229 | Train_Acc: 0.9926\n",
      "  Val_Loss: 0.0991 | Val_Acc: 0.9748\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0750 | current value= 0.0991\n",
      "Epoch 13/50\n",
      "  Train_Loss: 0.0203 | Train_Acc: 0.9931\n",
      "  Val_Loss: 0.0969 | Val_Acc: 0.9760\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0750 | current value= 0.0969\n",
      "Epoch 14/50\n",
      "  Train_Loss: 0.0194 | Train_Acc: 0.9934\n",
      "  Val_Loss: 0.1136 | Val_Acc: 0.9738\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.0750 | current value= 0.1136\n",
      "🛑Early stopping due to high risk of OVERFITTING\n",
      "Epoch 14: val_loss is INCREASING for 5 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▆▇▆██▇█▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▆▂▂▂▃▁▂▁▂▃▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_acc</td><td>0.99339</td></tr><tr><td>train_loss</td><td>0.01943</td></tr><tr><td>val_acc</td><td>0.97383</td></tr><tr><td>val_loss</td><td>0.11359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResidualMLP</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/AML_ResMLP/runs/2a1f40jc' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_ResMLP/runs/2a1f40jc</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/AML_ResMLP' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AML_ResMLP</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_195003-2a1f40jc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Hyperparameters of a \n",
    "input_size = 28 * 28\n",
    "hidden_size = 110\n",
    "num_blocks = 2\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# Creation and traning of ResidualMLP\n",
    "res_model = ResidualMLP(input_size, hidden_size, output_size, num_blocks, dropout_rate)\n",
    "res_optimizer = torch.optim.Adam(res_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, val_losses, res_epoch = train_model(\n",
    "    res_model, train_loader, val_loader, res_optimizer, criterion, num_epochs, device,\n",
    "    patience, min_delta, delta_overfit, overfit_patience,\n",
    "    wandb_project=\"AML_ResMLP\", wandb_run_name=\"ResidualMLP\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fdd05",
   "metadata": {},
   "source": [
    "### **ResMLP evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b5be087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test Loss: 0.0975 | Test Accuracy: 0.9773 | Test Precision: 0.9775\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on test set\n",
    "res_test_loss, res_test_acc, res_precision = evaluate(res_model, test_loader, criterion, device)\n",
    "print(f\"\\n{'-'*80}\")\n",
    "print(f\"Test Loss: {res_test_loss:.4f} | Test Accuracy: {res_test_acc:.4f} | Test Precision: {res_precision:.4f}\")\n",
    "print(f\"{'-'*80}\\n\")\n",
    "# Plot learning curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335de10b",
   "metadata": {},
   "source": [
    "### **Comparison Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c4ca332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "     ***** Comparison MLP vs ResidualMLP on TEST SET*****\n",
      "-----------------------------------------------------------------\n",
      "                | Epochs  | Loss       | Accuracy   | Precision \n",
      "-----------------------------------------------------------------\n",
      "MLP             | 17      | 0.1053     | 0.9739     | 0.9743    \n",
      "ResidualMLP     | 11      | 0.0975     | 0.9773     | 0.9775    \n",
      "\n",
      "**** MLP****\n",
      "\n",
      "fc1.weight grad norm: 0.1896\n",
      "fc2.weight grad norm: 0.1646\n",
      "out.weight grad norm: 0.1414\n",
      "\n",
      "**** ResidualMLP****\n",
      "\n",
      "fc1.weight grad norm: 0.4660\n",
      "blocks.0.fc1.weight grad norm: 0.3709\n",
      "blocks.0.fc2.weight grad norm: 0.1751\n",
      "blocks.1.fc1.weight grad norm: 0.2910\n",
      "blocks.1.fc2.weight grad norm: 0.1330\n",
      "fc2.weight grad norm: 0.4143\n"
     ]
    }
   ],
   "source": [
    "# Final performance comparison between MLP and ResidualMLP\n",
    "print(\"-\" * 65)\n",
    "\n",
    "print(f\"{' '*5}{'*'*5} Comparison MLP vs ResidualMLP on TEST SET{'*'*5}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'':<15} | {'Epochs':<7} | {'Loss':<10} | {'Accuracy':<10} | {'Precision':<10}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'MLP':<15} | {mlp_epoch:<7} | {mlp_test_loss:<10.4f} | {mlp_test_acc:<10.4f} | {mlp_precision:<10.4f}\")\n",
    "print(f\"{'ResidualMLP':<15} | {res_epoch:<7} | {res_test_loss:<10.4f} | {res_test_acc:<10.4f} | {res_precision:<10.4f}\\n\")\n",
    "\n",
    "# Printing of L2 norm of gradients for each layer (MLP) \n",
    "print(f\"{'*'*4} MLP{'*'*4}\\n\")\n",
    "for name, param in mlp_model.named_parameters():\n",
    "    if param.requires_grad and 'weight' in name:\n",
    "        print(f\"{name} grad norm: {param.grad.norm().item():.4f}\")\n",
    "\n",
    "# Printing of L2 norm of gradients for each layer (ResidualMLP) \n",
    "print(f\"\\n{'*'*4} ResidualMLP{'*'*4}\\n\")\n",
    "for name, param in res_model.named_parameters():\n",
    "    if param.requires_grad and 'weight' in name:\n",
    "        print(f\"{name} grad norm: {param.grad.norm().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59bdd8-3377-4311-b45f-511c2fb0b53e",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Rinse and Repeat (but with a CNN)\n",
    "\n",
    "Repeat the verification you did above, but with **Convolutional** Neural Networks. If you were careful about abstracting your model and training code, this should be a simple exercise. Show that **deeper** CNNs *without* residual connections do not always work better and **even deeper** ones *with* residual connections.\n",
    "\n",
    "**Hint**: You probably should do this exercise using CIFAR-10, since MNIST is *very* easy (at least up to about 99% accuracy).\n",
    "\n",
    "**Tip**: Feel free to reuse the ResNet building blocks defined in `torchvision.models.resnet` (e.g. [BasicBlock](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L59) which handles the cascade of 3x3 convolutions, skip connections, and optional downsampling). This is an excellent exercise in code diving. \n",
    "\n",
    "**Spoiler**: Depending on the optional exercises you plan to do below, you should think *very* carefully about the architectures of your CNNs here (so you can reuse them!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745752c",
   "metadata": {},
   "source": [
    "### **CIFAR-10 Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8baa0e-b17f-4a77-8a88-dadfdc6763ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "val_fraction=0.1\n",
    "\n",
    "def get_cifar10_transforms(train: bool = True):\n",
    "    # CIFAR-10 statistics (mean and std for RGB channels)\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std =  (0.2023, 0.1994, 0.2010)\n",
    "    \n",
    "\n",
    "    if train:\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),      \n",
    "            transforms.RandomHorizontalFlip(),         # Flip with p=0.5\n",
    "            transforms.ToTensor(),                     \n",
    "            transforms.Normalize(mean, std)            \n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "def load_cifar10_dataloaders(root='./data', val_fraction=val_fraction, batch_size=batch_size):\n",
    "    # Load datasets with correct transforms\n",
    "    train_val_dataset = CIFAR10(root=root, train=True, download=True, transform=get_cifar10_transforms(train=True))\n",
    "    test_dataset = CIFAR10(root=root, train=False, download=True, transform=get_cifar10_transforms(train=False))\n",
    "\n",
    "    # Split into train and validation\n",
    "    total_train = len(train_val_dataset)\n",
    "    val_size = int(total_train * val_fraction)\n",
    "    train_size = total_train - val_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "    # Replace transform for validation set\n",
    "    val_dataset.dataset.transform = get_cifar10_transforms(train=False)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_cifar10_dataloaders()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768417ee",
   "metadata": {},
   "source": [
    "## **SimpleCNN Model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9e1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VariableDepthCNN(nn.Module):\n",
    "    def __init__(self, num_layers, num_classes, base_channels, dropout_rate,in_channels,padding):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        # First conv layer: from 3 channels (RGB) to base_channels\n",
    "        out_channels = base_channels\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3,padding=padding))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            if i % 2 == 1:  # Every 2 layers, add max pooling\n",
    "                layers.append(nn.MaxPool2d(2))\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2  # Double channels after each layer\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "        # Compute the final output size\n",
    "        num_pools = num_layers // 2\n",
    "        final_feat_size = 32 // (2 ** num_pools)\n",
    "        final_channels = in_channels\n",
    "\n",
    "        self.fc1 = nn.Linear(final_channels * final_feat_size * final_feat_size, 128)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74a1d5",
   "metadata": {},
   "source": [
    "### ***SimpleCNN traning and evalution***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95684c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_144454-7ai0bu4w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN/runs/7ai0bu4w' target=\"_blank\">SimpleCNN</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN/runs/7ai0bu4w' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN/runs/7ai0bu4w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  Train_Loss: 1.4391 | Train_Acc: 0.4801\n",
      "  Val_Loss: 1.0289 | Val_Acc: 0.6284\n",
      "\n",
      "Epoch 2/50\n",
      "  Train_Loss: 0.9214 | Train_Acc: 0.6754\n",
      "  Val_Loss: 0.7848 | Val_Acc: 0.7150\n",
      "\n",
      "Epoch 3/50\n",
      "  Train_Loss: 0.7165 | Train_Acc: 0.7507\n",
      "  Val_Loss: 0.6905 | Val_Acc: 0.7586\n",
      "\n",
      "Epoch 4/50\n",
      "  Train_Loss: 0.5628 | Train_Acc: 0.8036\n",
      "  Val_Loss: 0.6531 | Val_Acc: 0.7714\n",
      "\n",
      "Epoch 5/50\n",
      "  Train_Loss: 0.4387 | Train_Acc: 0.8440\n",
      "  Val_Loss: 0.6552 | Val_Acc: 0.7792\n",
      "\n",
      "Epoch 6/50\n",
      "  Train_Loss: 0.3362 | Train_Acc: 0.8826\n",
      "  Val_Loss: 0.6966 | Val_Acc: 0.7764\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6531 | current value= 0.6966\n",
      "Epoch 7/50\n",
      "  Train_Loss: 0.2526 | Train_Acc: 0.9094\n",
      "  Val_Loss: 0.7268 | Val_Acc: 0.7836\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6531 | current value= 0.7268\n",
      "Epoch 8/50\n",
      "  Train_Loss: 0.1986 | Train_Acc: 0.9296\n",
      "  Val_Loss: 0.8021 | Val_Acc: 0.7872\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6531 | current value= 0.8021\n",
      "Epoch 9/50\n",
      "  Train_Loss: 0.1588 | Train_Acc: 0.9440\n",
      "  Val_Loss: 0.8372 | Val_Acc: 0.7952\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6531 | current value= 0.8372\n",
      "Epoch 10/50\n",
      "  Train_Loss: 0.1319 | Train_Acc: 0.9538\n",
      "  Val_Loss: 0.9448 | Val_Acc: 0.7850\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6531 | current value= 0.9448\n",
      "🛑Early stopping due to high risk of OVERFITTING\n",
      "Epoch 10: val_loss is INCREASING for 5 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▂▂▄▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.95382</td></tr><tr><td>train_loss</td><td>0.13188</td></tr><tr><td>val_acc</td><td>0.785</td></tr><tr><td>val_loss</td><td>0.94481</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SimpleCNN</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN/runs/7ai0bu4w' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN/runs/7ai0bu4w</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/AMLP_SimpleCNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_144454-7ai0bu4w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN performance on TEST SET\n",
      "----------------------------------------------------------------------\n",
      "|Model              | Epochs  | Loss       | Accuracy   | Precision |\n",
      "----------------------------------------------------------------------\n",
      "|SimpleCNN [4Layer] | 10      | 1.0038     | 0.7766     | 0.7842    |\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters and configuration\n",
    "num_layers = 4    \n",
    "      \n",
    "num_classes = 10         \n",
    "base_channels = 32       \n",
    "dropout_rate = 0.2\n",
    "\n",
    "in_channels = 3   # Input channels (RGB images → 3 channels)\n",
    "\n",
    "padding = 1              \n",
    "learning_rate = 0.001   \n",
    "num_epochs = 50        \n",
    "patience = 5           \n",
    "min_delta = 0.001        \n",
    "delta_overfit = 0.01  \n",
    "overfit_patience = 5   \n",
    "\n",
    "# Instantiate CNN model\n",
    "cnn_model = VariableDepthCNN(\n",
    "    num_layers, num_classes, base_channels, dropout_rate, in_channels, padding\n",
    ").to(device)\n",
    "\n",
    "# optimizer and loss function\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Train the CNN\n",
    "train_losses_cnn, val_losses_cnn, epochs_cnn = train_model(\n",
    "    cnn_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    cnn_optimizer,\n",
    "    criterion,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    patience,\n",
    "    min_delta,\n",
    "    delta_overfit,\n",
    "    overfit_patience,\n",
    "    wandb_project=\"AMLP_SimpleCNN\",        \n",
    "    wandb_run_name=\"SimpleCNN\"\n",
    ")\n",
    "\n",
    "# Evaluation \n",
    "test_loss_cnn, test_acc_cnn, test_prec_cnn = evaluate(\n",
    "    cnn_model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "\n",
    "#print results\n",
    "print(\"SimpleCNN performance on TEST SET\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"|{'Model':<18} | {'Epochs':<7} | {'Loss':<10} | {'Accuracy':<10} | {'Precision':<10}|\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"|{f'SimpleCNN [{num_layers}Layer]':<15} | {epochs_cnn:<7} | {test_loss_cnn:<10.4f} | {test_acc_cnn:<10.4f} | {test_prec_cnn:<10.4f}|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a82e0",
   "metadata": {},
   "source": [
    "## **ResidualCNN architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b494bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VariableDepthResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes, base_channels, dropout_rate, in_channels, padding):\n",
    "        super().__init__()\n",
    "        # Initial convolution + batch norm + activation\n",
    "        self.conv1 = nn.Conv2d(in_channels, base_channels, kernel_size=3, padding=padding, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(base_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Stack residual blocks\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(BasicBlock(base_channels, base_channels))\n",
    "        self.res_blocks = nn.Sequential(*layers)\n",
    "\n",
    "        # Global average pooling\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Dropout + final classifier\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(base_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))  \n",
    "        x = self.res_blocks(x)                  \n",
    "        x = self.pool(x)                       \n",
    "        x = torch.flatten(x, 1)                  \n",
    "        x = self.dropout(x)                     \n",
    "        return self.fc(x)                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa43a1",
   "metadata": {},
   "source": [
    "### ***ResidualCNN traning e evaluation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a3df05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m num_blocks=\u001b[32m4\u001b[39m    \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Instantiate Residual CNN model\u001b[39;00m\n\u001b[32m      5\u001b[39m ResCnn_model = VariableDepthResNet(\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     num_blocks, \u001b[43mnum_classes\u001b[49m, base_channels, dropout_rate, in_channels, padding\n\u001b[32m      7\u001b[39m ).to(device)\n\u001b[32m     10\u001b[39m ResCnn_optimizer = torch.optim.Adam(ResCnn_model.parameters(), lr=learning_rate)\n\u001b[32m     11\u001b[39m criterion = nn.CrossEntropyLoss() \n",
      "\u001b[31mNameError\u001b[39m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters \n",
    "num_blocks=4    \n",
    "\n",
    "# Instantiate Residual CNN model\n",
    "ResCnn_model = VariableDepthResNet(\n",
    "    num_blocks, num_classes, base_channels, dropout_rate, in_channels, padding\n",
    ").to(device)\n",
    "\n",
    "\n",
    "ResCnn_optimizer = torch.optim.Adam(ResCnn_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Train \n",
    "train_losses_rescnn, val_losses_rescnn, epochs_rescnn = train_model(\n",
    "    ResCnn_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    ResCnn_optimizer,\n",
    "    criterion,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    patience,\n",
    "    min_delta,\n",
    "    delta_overfit,\n",
    "    overfit_patience,\n",
    "    wandb_project=\"AML_ResCNN\",        \n",
    "    wandb_run_name=\"ResidualCNN\"\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss_rescnn, test_acc_rescnn, test_prec_rescnn = evaluate(\n",
    "    ResCnn_model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "\n",
    "#print results\n",
    "print(\"ResidualCNN performance on TEST SET\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"|{'Model':<18} | {'Epochs':<7} | {'Loss':<10} | {'Accuracy':<10} | {'Precision':<10}|\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"|{f'ResidualCNN [{num_blocks}Layer]':<15} | {epochs_rescnn:<7} | {test_loss_rescnn:<10.4f} | {test_acc_rescnn:<10.4f} | {test_prec_rescnn:<10.4f}|\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809140f",
   "metadata": {},
   "source": [
    "### **Comparison SimpleCNN and ResidualCNN for different depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing depth = 2 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_094714-elor89fr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/elor89fr' target=\"_blank\">SimpleCNN_2Layers</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/elor89fr' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/elor89fr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  Train_Loss: 1.4238 | Train_Acc: 0.4909\n",
      "  Val_Loss: 1.0581 | Val_Acc: 0.6194\n",
      "\n",
      "Epoch 2/30\n",
      "  Train_Loss: 1.0082 | Train_Acc: 0.6452\n",
      "  Val_Loss: 0.9264 | Val_Acc: 0.6698\n",
      "\n",
      "Epoch 3/30\n",
      "  Train_Loss: 0.8402 | Train_Acc: 0.7031\n",
      "  Val_Loss: 0.8985 | Val_Acc: 0.6838\n",
      "\n",
      "Epoch 4/30\n",
      "  Train_Loss: 0.7133 | Train_Acc: 0.7482\n",
      "  Val_Loss: 0.8832 | Val_Acc: 0.6910\n",
      "\n",
      "Epoch 5/30\n",
      "  Train_Loss: 0.6033 | Train_Acc: 0.7853\n",
      "  Val_Loss: 0.8929 | Val_Acc: 0.6946\n",
      "\n",
      "Epoch 6/30\n",
      "  Train_Loss: 0.5011 | Train_Acc: 0.8198\n",
      "  Val_Loss: 0.9382 | Val_Acc: 0.7044\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 0.9382\n",
      "Epoch 7/30\n",
      "  Train_Loss: 0.4110 | Train_Acc: 0.8544\n",
      "  Val_Loss: 0.9748 | Val_Acc: 0.7054\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 0.9748\n",
      "Epoch 8/30\n",
      "  Train_Loss: 0.3436 | Train_Acc: 0.8775\n",
      "  Val_Loss: 1.0267 | Val_Acc: 0.6936\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 1.0267\n",
      "Epoch 9/30\n",
      "  Train_Loss: 0.2843 | Train_Acc: 0.8985\n",
      "  Val_Loss: 1.0994 | Val_Acc: 0.6914\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 1.0994\n",
      "Epoch 10/30\n",
      "  Train_Loss: 0.2445 | Train_Acc: 0.9125\n",
      "  Val_Loss: 1.1416 | Val_Acc: 0.7010\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 1.1416\n",
      "Epoch 11/30\n",
      "  Train_Loss: 0.2114 | Train_Acc: 0.9236\n",
      "  Val_Loss: 1.3054 | Val_Acc: 0.6980\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 1.3054\n",
      "Epoch 12/30\n",
      "  Train_Loss: 0.1877 | Train_Acc: 0.9334\n",
      "  Val_Loss: 1.3600 | Val_Acc: 0.6974\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 1.3600\n",
      "Epoch 13/30\n",
      "  Train_Loss: 0.1734 | Train_Acc: 0.9379\n",
      "  Val_Loss: 1.4206 | Val_Acc: 0.6872\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8832 | current value= 1.4206\n",
      "🛑Early stopping due to high risk of OVERFITTING\n",
      "Epoch 13: val_loss is INCREASING for 8 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇██▇▇█▇▇▇</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▂▂▃▄▄▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>train_acc</td><td>0.93787</td></tr><tr><td>train_loss</td><td>0.17336</td></tr><tr><td>val_acc</td><td>0.6872</td></tr><tr><td>val_loss</td><td>1.42057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SimpleCNN_2Layers</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/elor89fr' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/elor89fr</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_094714-elor89fr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_095933-9l4d16nm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/9l4d16nm' target=\"_blank\">ResidualCNN_2Blocks</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/9l4d16nm' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/9l4d16nm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  Train_Loss: 1.6673 | Train_Acc: 0.3786\n",
      "  Val_Loss: 1.5608 | Val_Acc: 0.4268\n",
      "\n",
      "Epoch 2/30\n",
      "  Train_Loss: 1.3708 | Train_Acc: 0.5002\n",
      "  Val_Loss: 1.4736 | Val_Acc: 0.4746\n",
      "\n",
      "Epoch 3/30\n",
      "  Train_Loss: 1.2408 | Train_Acc: 0.5534\n",
      "  Val_Loss: 1.2450 | Val_Acc: 0.5632\n",
      "\n",
      "Epoch 4/30\n",
      "  Train_Loss: 1.1588 | Train_Acc: 0.5844\n",
      "  Val_Loss: 1.0771 | Val_Acc: 0.6240\n",
      "\n",
      "Epoch 5/30\n",
      "  Train_Loss: 1.0889 | Train_Acc: 0.6121\n",
      "  Val_Loss: 1.1883 | Val_Acc: 0.5830\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 1.0771 | current value= 1.1883\n",
      "Epoch 6/30\n",
      "  Train_Loss: 1.0367 | Train_Acc: 0.6297\n",
      "  Val_Loss: 1.0939 | Val_Acc: 0.6082\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 1.0771 | current value= 1.0939\n",
      "Epoch 7/30\n",
      "  Train_Loss: 0.9841 | Train_Acc: 0.6527\n",
      "  Val_Loss: 0.9344 | Val_Acc: 0.6624\n",
      "\n",
      "Epoch 8/30\n",
      "  Train_Loss: 0.9452 | Train_Acc: 0.6626\n",
      "  Val_Loss: 1.0158 | Val_Acc: 0.6488\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.9344 | current value= 1.0158\n",
      "Epoch 9/30\n",
      "  Train_Loss: 0.9091 | Train_Acc: 0.6781\n",
      "  Val_Loss: 0.9973 | Val_Acc: 0.6420\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.9344 | current value= 0.9973\n",
      "Epoch 10/30\n",
      "  Train_Loss: 0.8801 | Train_Acc: 0.6888\n",
      "  Val_Loss: 1.3211 | Val_Acc: 0.5606\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.9344 | current value= 1.3211\n",
      "Epoch 11/30\n",
      "  Train_Loss: 0.8528 | Train_Acc: 0.6957\n",
      "  Val_Loss: 0.7706 | Val_Acc: 0.7300\n",
      "\n",
      "Epoch 12/30\n",
      "  Train_Loss: 0.8280 | Train_Acc: 0.7078\n",
      "  Val_Loss: 0.7950 | Val_Acc: 0.7180\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7706 | current value= 0.7950\n",
      "Epoch 13/30\n",
      "  Train_Loss: 0.8076 | Train_Acc: 0.7143\n",
      "  Val_Loss: 0.8550 | Val_Acc: 0.6934\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7706 | current value= 0.8550\n",
      "Epoch 14/30\n",
      "  Train_Loss: 0.7807 | Train_Acc: 0.7247\n",
      "  Val_Loss: 0.7754 | Val_Acc: 0.7268\n",
      "\n",
      "Epoch 15/30\n",
      "  Train_Loss: 0.7601 | Train_Acc: 0.7340\n",
      "  Val_Loss: 0.7309 | Val_Acc: 0.7420\n",
      "\n",
      "Epoch 16/30\n",
      "  Train_Loss: 0.7421 | Train_Acc: 0.7386\n",
      "  Val_Loss: 0.8179 | Val_Acc: 0.7116\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7309 | current value= 0.8179\n",
      "Epoch 17/30\n",
      "  Train_Loss: 0.7301 | Train_Acc: 0.7431\n",
      "  Val_Loss: 0.6932 | Val_Acc: 0.7650\n",
      "\n",
      "Epoch 18/30\n",
      "  Train_Loss: 0.7109 | Train_Acc: 0.7512\n",
      "  Val_Loss: 0.7449 | Val_Acc: 0.7402\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6932 | current value= 0.7449\n",
      "Epoch 19/30\n",
      "  Train_Loss: 0.6916 | Train_Acc: 0.7581\n",
      "  Val_Loss: 0.7451 | Val_Acc: 0.7390\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6932 | current value= 0.7451\n",
      "⚠️Δ(val_loss) < 0.001 for 1 consecutive epoch(s)\n",
      "Epoch 20/30\n",
      "  Train_Loss: 0.6832 | Train_Acc: 0.7616\n",
      "  Val_Loss: 0.7750 | Val_Acc: 0.7272\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6932 | current value= 0.7750\n",
      "Epoch 21/30\n",
      "  Train_Loss: 0.6617 | Train_Acc: 0.7693\n",
      "  Val_Loss: 0.6666 | Val_Acc: 0.7656\n",
      "\n",
      "Epoch 22/30\n",
      "  Train_Loss: 0.6436 | Train_Acc: 0.7731\n",
      "  Val_Loss: 0.6769 | Val_Acc: 0.7660\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6666 | current value= 0.6769\n",
      "Epoch 23/30\n",
      "  Train_Loss: 0.6399 | Train_Acc: 0.7783\n",
      "  Val_Loss: 0.6620 | Val_Acc: 0.7684\n",
      "\n",
      "Epoch 24/30\n",
      "  Train_Loss: 0.6267 | Train_Acc: 0.7812\n",
      "  Val_Loss: 0.6794 | Val_Acc: 0.7670\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6620 | current value= 0.6794\n",
      "Epoch 25/30\n",
      "  Train_Loss: 0.6186 | Train_Acc: 0.7838\n",
      "  Val_Loss: 0.6164 | Val_Acc: 0.7862\n",
      "\n",
      "Epoch 26/30\n",
      "  Train_Loss: 0.6021 | Train_Acc: 0.7914\n",
      "  Val_Loss: 0.6050 | Val_Acc: 0.7944\n",
      "\n",
      "Epoch 27/30\n",
      "  Train_Loss: 0.5958 | Train_Acc: 0.7910\n",
      "  Val_Loss: 0.6270 | Val_Acc: 0.7810\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6050 | current value= 0.6270\n",
      "Epoch 28/30\n",
      "  Train_Loss: 0.5773 | Train_Acc: 0.7979\n",
      "  Val_Loss: 0.8500 | Val_Acc: 0.7172\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6050 | current value= 0.8500\n",
      "Epoch 29/30\n",
      "  Train_Loss: 0.5671 | Train_Acc: 0.8029\n",
      "  Val_Loss: 0.6481 | Val_Acc: 0.7750\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6050 | current value= 0.6481\n",
      "Epoch 30/30\n",
      "  Train_Loss: 0.5590 | Train_Acc: 0.8056\n",
      "  Val_Loss: 0.6628 | Val_Acc: 0.7696\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6050 | current value= 0.6628\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▄▅▄▄▅▅▅▄▇▇▆▇▇▆▇▇▇▇▇▇█▇███▇██</td></tr><tr><td>val_loss</td><td>█▇▆▄▅▅▃▄▄▆▂▂▃▂▂▃▂▂▂▂▁▂▁▂▁▁▁▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_acc</td><td>0.80564</td></tr><tr><td>train_loss</td><td>0.55903</td></tr><tr><td>val_acc</td><td>0.7696</td></tr><tr><td>val_loss</td><td>0.66281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResidualCNN_2Blocks</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/9l4d16nm' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/9l4d16nm</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_095933-9l4d16nm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing depth = 3 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_102105-aj4t530p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/aj4t530p' target=\"_blank\">SimpleCNN_3Layers</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/aj4t530p' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/aj4t530p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  Train_Loss: 1.4060 | Train_Acc: 0.4964\n",
      "  Val_Loss: 1.0567 | Val_Acc: 0.6244\n",
      "\n",
      "Epoch 2/30\n",
      "  Train_Loss: 0.9609 | Train_Acc: 0.6626\n",
      "  Val_Loss: 0.8374 | Val_Acc: 0.7120\n",
      "\n",
      "Epoch 3/30\n",
      "  Train_Loss: 0.7694 | Train_Acc: 0.7311\n",
      "  Val_Loss: 0.7628 | Val_Acc: 0.7350\n",
      "\n",
      "Epoch 4/30\n",
      "  Train_Loss: 0.6249 | Train_Acc: 0.7808\n",
      "  Val_Loss: 0.7433 | Val_Acc: 0.7468\n",
      "\n",
      "Epoch 5/30\n",
      "  Train_Loss: 0.4909 | Train_Acc: 0.8266\n",
      "  Val_Loss: 0.7591 | Val_Acc: 0.7488\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 0.7591\n",
      "Epoch 6/30\n",
      "  Train_Loss: 0.3866 | Train_Acc: 0.8592\n",
      "  Val_Loss: 0.7981 | Val_Acc: 0.7546\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 0.7981\n",
      "Epoch 7/30\n",
      "  Train_Loss: 0.3002 | Train_Acc: 0.8940\n",
      "  Val_Loss: 0.8758 | Val_Acc: 0.7486\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 0.8758\n",
      "Epoch 8/30\n",
      "  Train_Loss: 0.2366 | Train_Acc: 0.9163\n",
      "  Val_Loss: 0.9912 | Val_Acc: 0.7440\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 0.9912\n",
      "Epoch 9/30\n",
      "  Train_Loss: 0.1879 | Train_Acc: 0.9328\n",
      "  Val_Loss: 1.0209 | Val_Acc: 0.7558\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 1.0209\n",
      "Epoch 10/30\n",
      "  Train_Loss: 0.1605 | Train_Acc: 0.9415\n",
      "  Val_Loss: 1.0791 | Val_Acc: 0.7498\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 1.0791\n",
      "Epoch 11/30\n",
      "  Train_Loss: 0.1420 | Train_Acc: 0.9490\n",
      "  Val_Loss: 1.1386 | Val_Acc: 0.7448\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 1.1386\n",
      "Epoch 12/30\n",
      "  Train_Loss: 0.1272 | Train_Acc: 0.9543\n",
      "  Val_Loss: 1.1658 | Val_Acc: 0.7552\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7433 | current value= 1.1658\n",
      "🛑Early stopping due to high risk of OVERFITTING\n",
      "Epoch 12: val_loss is INCREASING for 8 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▇████▇██▇█</td></tr><tr><td>val_loss</td><td>▆▃▁▁▁▂▃▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>12</td></tr><tr><td>train_acc</td><td>0.95431</td></tr><tr><td>train_loss</td><td>0.12718</td></tr><tr><td>val_acc</td><td>0.7552</td></tr><tr><td>val_loss</td><td>1.16578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SimpleCNN_3Layers</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/aj4t530p' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/aj4t530p</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_102105-aj4t530p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_102720-2d52rqx3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2d52rqx3' target=\"_blank\">ResidualCNN_3Blocks</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2d52rqx3' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2d52rqx3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  Train_Loss: 1.5976 | Train_Acc: 0.4097\n",
      "  Val_Loss: 1.4336 | Val_Acc: 0.4798\n",
      "\n",
      "Epoch 2/30\n",
      "  Train_Loss: 1.2760 | Train_Acc: 0.5366\n",
      "  Val_Loss: 1.1264 | Val_Acc: 0.6002\n",
      "\n",
      "Epoch 3/30\n",
      "  Train_Loss: 1.1292 | Train_Acc: 0.5934\n",
      "  Val_Loss: 1.0962 | Val_Acc: 0.6108\n",
      "\n",
      "Epoch 4/30\n",
      "  Train_Loss: 1.0394 | Train_Acc: 0.6308\n",
      "  Val_Loss: 0.9689 | Val_Acc: 0.6528\n",
      "\n",
      "Epoch 5/30\n",
      "  Train_Loss: 0.9621 | Train_Acc: 0.6568\n",
      "  Val_Loss: 0.9789 | Val_Acc: 0.6548\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.9689 | current value= 0.9789\n",
      "Epoch 6/30\n",
      "  Train_Loss: 0.9062 | Train_Acc: 0.6789\n",
      "  Val_Loss: 1.0961 | Val_Acc: 0.6056\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.9689 | current value= 1.0961\n",
      "Epoch 7/30\n",
      "  Train_Loss: 0.8573 | Train_Acc: 0.6985\n",
      "  Val_Loss: 0.8109 | Val_Acc: 0.7166\n",
      "\n",
      "Epoch 8/30\n",
      "  Train_Loss: 0.8148 | Train_Acc: 0.7127\n",
      "  Val_Loss: 0.8214 | Val_Acc: 0.7100\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.8109 | current value= 0.8214\n",
      "Epoch 9/30\n",
      "  Train_Loss: 0.7773 | Train_Acc: 0.7290\n",
      "  Val_Loss: 0.7679 | Val_Acc: 0.7372\n",
      "\n",
      "Epoch 10/30\n",
      "  Train_Loss: 0.7435 | Train_Acc: 0.7415\n",
      "  Val_Loss: 0.7929 | Val_Acc: 0.7160\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7679 | current value= 0.7929\n",
      "Epoch 11/30\n",
      "  Train_Loss: 0.7089 | Train_Acc: 0.7524\n",
      "  Val_Loss: 0.9525 | Val_Acc: 0.6776\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7679 | current value= 0.9525\n",
      "Epoch 12/30\n",
      "  Train_Loss: 0.6814 | Train_Acc: 0.7632\n",
      "  Val_Loss: 0.8322 | Val_Acc: 0.7180\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7679 | current value= 0.8322\n",
      "Epoch 13/30\n",
      "  Train_Loss: 0.6564 | Train_Acc: 0.7710\n",
      "  Val_Loss: 0.7715 | Val_Acc: 0.7400\n",
      "\n",
      "Epoch 14/30\n",
      "  Train_Loss: 0.6264 | Train_Acc: 0.7811\n",
      "  Val_Loss: 0.8224 | Val_Acc: 0.7042\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7679 | current value= 0.8224\n",
      "Epoch 15/30\n",
      "  Train_Loss: 0.5994 | Train_Acc: 0.7944\n",
      "  Val_Loss: 0.6143 | Val_Acc: 0.7866\n",
      "\n",
      "Epoch 16/30\n",
      "  Train_Loss: 0.5815 | Train_Acc: 0.7983\n",
      "  Val_Loss: 0.6015 | Val_Acc: 0.7946\n",
      "\n",
      "Epoch 17/30\n",
      "  Train_Loss: 0.5555 | Train_Acc: 0.8054\n",
      "  Val_Loss: 0.7052 | Val_Acc: 0.7640\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6015 | current value= 0.7052\n",
      "Epoch 18/30\n",
      "  Train_Loss: 0.5372 | Train_Acc: 0.8130\n",
      "  Val_Loss: 0.6505 | Val_Acc: 0.7774\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6015 | current value= 0.6505\n",
      "Epoch 19/30\n",
      "  Train_Loss: 0.5202 | Train_Acc: 0.8191\n",
      "  Val_Loss: 0.6620 | Val_Acc: 0.7716\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6015 | current value= 0.6620\n",
      "Epoch 20/30\n",
      "  Train_Loss: 0.5041 | Train_Acc: 0.8262\n",
      "  Val_Loss: 0.6185 | Val_Acc: 0.7930\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6015 | current value= 0.6185\n",
      "Epoch 21/30\n",
      "  Train_Loss: 0.4840 | Train_Acc: 0.8316\n",
      "  Val_Loss: 0.6474 | Val_Acc: 0.7804\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6015 | current value= 0.6474\n",
      "Epoch 22/30\n",
      "  Train_Loss: 0.4685 | Train_Acc: 0.8383\n",
      "  Val_Loss: 0.6093 | Val_Acc: 0.7984\n",
      "\n",
      "Epoch 23/30\n",
      "  Train_Loss: 0.4524 | Train_Acc: 0.8442\n",
      "  Val_Loss: 0.5739 | Val_Acc: 0.8028\n",
      "\n",
      "Epoch 24/30\n",
      "  Train_Loss: 0.4387 | Train_Acc: 0.8486\n",
      "  Val_Loss: 0.5287 | Val_Acc: 0.8158\n",
      "\n",
      "Epoch 25/30\n",
      "  Train_Loss: 0.4206 | Train_Acc: 0.8533\n",
      "  Val_Loss: 0.6116 | Val_Acc: 0.7976\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5287 | current value= 0.6116\n",
      "Epoch 26/30\n",
      "  Train_Loss: 0.4141 | Train_Acc: 0.8571\n",
      "  Val_Loss: 0.6727 | Val_Acc: 0.7746\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5287 | current value= 0.6727\n",
      "Epoch 27/30\n",
      "  Train_Loss: 0.3941 | Train_Acc: 0.8629\n",
      "  Val_Loss: 0.5762 | Val_Acc: 0.8080\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5287 | current value= 0.5762\n",
      "Epoch 28/30\n",
      "  Train_Loss: 0.3832 | Train_Acc: 0.8673\n",
      "  Val_Loss: 0.7414 | Val_Acc: 0.7796\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5287 | current value= 0.7414\n",
      "Epoch 29/30\n",
      "  Train_Loss: 0.3666 | Train_Acc: 0.8733\n",
      "  Val_Loss: 0.6184 | Val_Acc: 0.8026\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5287 | current value= 0.6184\n",
      "Epoch 30/30\n",
      "  Train_Loss: 0.3531 | Train_Acc: 0.8783\n",
      "  Val_Loss: 0.6185 | Val_Acc: 0.8070\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5287 | current value= 0.6185\n",
      "⚠️Δ(val_loss) < 0.001 for 1 consecutive epoch(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▄▅▅▄▆▆▆▆▅▆▆▆▇█▇▇▇█▇████▇█▇██</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▅▃▃▃▃▄▃▃▃▂▂▂▂▂▂▂▂▁▁▂▂▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_acc</td><td>0.87833</td></tr><tr><td>train_loss</td><td>0.35308</td></tr><tr><td>val_acc</td><td>0.807</td></tr><tr><td>val_loss</td><td>0.61852</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResidualCNN_3Blocks</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2d52rqx3' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2d52rqx3</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_102720-2d52rqx3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing depth = 6 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_105332-ht0kvux3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/ht0kvux3' target=\"_blank\">SimpleCNN_6Layers</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/ht0kvux3' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/ht0kvux3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  Train_Loss: 1.6141 | Train_Acc: 0.3969\n",
      "  Val_Loss: 1.2392 | Val_Acc: 0.5500\n",
      "\n",
      "Epoch 2/30\n",
      "  Train_Loss: 1.0927 | Train_Acc: 0.6100\n",
      "  Val_Loss: 0.8920 | Val_Acc: 0.6890\n",
      "\n",
      "Epoch 3/30\n",
      "  Train_Loss: 0.8365 | Train_Acc: 0.7085\n",
      "  Val_Loss: 0.8616 | Val_Acc: 0.7062\n",
      "\n",
      "Epoch 4/30\n",
      "  Train_Loss: 0.6781 | Train_Acc: 0.7659\n",
      "  Val_Loss: 0.6529 | Val_Acc: 0.7770\n",
      "\n",
      "Epoch 5/30\n",
      "  Train_Loss: 0.5516 | Train_Acc: 0.8084\n",
      "  Val_Loss: 0.6422 | Val_Acc: 0.7830\n",
      "\n",
      "Epoch 6/30\n",
      "  Train_Loss: 0.4444 | Train_Acc: 0.8453\n",
      "  Val_Loss: 0.6655 | Val_Acc: 0.7800\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6422 | current value= 0.6655\n",
      "Epoch 7/30\n",
      "  Train_Loss: 0.3593 | Train_Acc: 0.8751\n",
      "  Val_Loss: 0.6380 | Val_Acc: 0.7978\n",
      "\n",
      "Epoch 8/30\n",
      "  Train_Loss: 0.2908 | Train_Acc: 0.8982\n",
      "  Val_Loss: 0.6761 | Val_Acc: 0.8018\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.6761\n",
      "Epoch 9/30\n",
      "  Train_Loss: 0.2145 | Train_Acc: 0.9261\n",
      "  Val_Loss: 0.6809 | Val_Acc: 0.8082\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.6809\n",
      "Epoch 10/30\n",
      "  Train_Loss: 0.1825 | Train_Acc: 0.9372\n",
      "  Val_Loss: 0.7725 | Val_Acc: 0.8068\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.7725\n",
      "Epoch 11/30\n",
      "  Train_Loss: 0.1590 | Train_Acc: 0.9454\n",
      "  Val_Loss: 0.8454 | Val_Acc: 0.8034\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.8454\n",
      "Epoch 12/30\n",
      "  Train_Loss: 0.1251 | Train_Acc: 0.9558\n",
      "  Val_Loss: 0.8870 | Val_Acc: 0.8114\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.8870\n",
      "Epoch 13/30\n",
      "  Train_Loss: 0.1176 | Train_Acc: 0.9610\n",
      "  Val_Loss: 0.8998 | Val_Acc: 0.8120\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.8998\n",
      "Epoch 14/30\n",
      "  Train_Loss: 0.1060 | Train_Acc: 0.9643\n",
      "  Val_Loss: 0.9835 | Val_Acc: 0.8030\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.9835\n",
      "Epoch 15/30\n",
      "  Train_Loss: 0.0980 | Train_Acc: 0.9659\n",
      "  Val_Loss: 0.9524 | Val_Acc: 0.8074\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6380 | current value= 0.9524\n",
      "🛑Early stopping due to high risk of OVERFITTING\n",
      "Epoch 15: val_loss is INCREASING for 8 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▄▄▁▁▁▁▁▁▃▃▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>0.96589</td></tr><tr><td>train_loss</td><td>0.09801</td></tr><tr><td>val_acc</td><td>0.8074</td></tr><tr><td>val_loss</td><td>0.95245</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SimpleCNN_6Layers</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/ht0kvux3' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/ht0kvux3</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_105332-ht0kvux3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\UNIFI\\LM Bio UniFi\\II ANNO\\SECONDO SEMESTRE\\APPLI OF MACHINE LEARNING\\AML_Labs\\Exercise\\wandb\\run-20250805_110810-2dw0nydb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2dw0nydb' target=\"_blank\">ResidualCNN_6Blocks</a></strong> to <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2dw0nydb' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2dw0nydb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  Train_Loss: 1.5973 | Train_Acc: 0.4086\n",
      "  Val_Loss: 1.4196 | Val_Acc: 0.4854\n",
      "\n",
      "Epoch 2/30\n",
      "  Train_Loss: 1.2333 | Train_Acc: 0.5537\n",
      "  Val_Loss: 1.1994 | Val_Acc: 0.5684\n",
      "\n",
      "Epoch 3/30\n",
      "  Train_Loss: 1.0717 | Train_Acc: 0.6143\n",
      "  Val_Loss: 1.0683 | Val_Acc: 0.6210\n",
      "\n",
      "Epoch 4/30\n",
      "  Train_Loss: 0.9706 | Train_Acc: 0.6548\n",
      "  Val_Loss: 0.9374 | Val_Acc: 0.6610\n",
      "\n",
      "Epoch 5/30\n",
      "  Train_Loss: 0.8819 | Train_Acc: 0.6878\n",
      "  Val_Loss: 1.7216 | Val_Acc: 0.4964\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.9374 | current value= 1.7216\n",
      "Epoch 6/30\n",
      "  Train_Loss: 0.8066 | Train_Acc: 0.7180\n",
      "  Val_Loss: 0.9211 | Val_Acc: 0.6628\n",
      "\n",
      "Epoch 7/30\n",
      "  Train_Loss: 0.7459 | Train_Acc: 0.7380\n",
      "  Val_Loss: 0.9328 | Val_Acc: 0.6790\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.9211 | current value= 0.9328\n",
      "Epoch 8/30\n",
      "  Train_Loss: 0.6864 | Train_Acc: 0.7632\n",
      "  Val_Loss: 0.7349 | Val_Acc: 0.7382\n",
      "\n",
      "Epoch 9/30\n",
      "  Train_Loss: 0.6303 | Train_Acc: 0.7843\n",
      "  Val_Loss: 0.8150 | Val_Acc: 0.7248\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.7349 | current value= 0.8150\n",
      "Epoch 10/30\n",
      "  Train_Loss: 0.5868 | Train_Acc: 0.8008\n",
      "  Val_Loss: 0.6841 | Val_Acc: 0.7654\n",
      "\n",
      "Epoch 11/30\n",
      "  Train_Loss: 0.5458 | Train_Acc: 0.8167\n",
      "  Val_Loss: 0.7067 | Val_Acc: 0.7576\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.6841 | current value= 0.7067\n",
      "Epoch 12/30\n",
      "  Train_Loss: 0.5137 | Train_Acc: 0.8238\n",
      "  Val_Loss: 0.6595 | Val_Acc: 0.7738\n",
      "\n",
      "Epoch 13/30\n",
      "  Train_Loss: 0.4785 | Train_Acc: 0.8357\n",
      "  Val_Loss: 0.5957 | Val_Acc: 0.7932\n",
      "\n",
      "Epoch 14/30\n",
      "  Train_Loss: 0.4470 | Train_Acc: 0.8475\n",
      "  Val_Loss: 0.5615 | Val_Acc: 0.8044\n",
      "\n",
      "Epoch 15/30\n",
      "  Train_Loss: 0.4194 | Train_Acc: 0.8577\n",
      "  Val_Loss: 0.5291 | Val_Acc: 0.8238\n",
      "\n",
      "Epoch 16/30\n",
      "  Train_Loss: 0.4024 | Train_Acc: 0.8632\n",
      "  Val_Loss: 0.6567 | Val_Acc: 0.7964\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5291 | current value= 0.6567\n",
      "Epoch 17/30\n",
      "  Train_Loss: 0.3765 | Train_Acc: 0.8733\n",
      "  Val_Loss: 0.6794 | Val_Acc: 0.7792\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5291 | current value= 0.6794\n",
      "Epoch 18/30\n",
      "  Train_Loss: 0.3594 | Train_Acc: 0.8755\n",
      "  Val_Loss: 0.5455 | Val_Acc: 0.8214\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.5291 | current value= 0.5455\n",
      "Epoch 19/30\n",
      "  Train_Loss: 0.3332 | Train_Acc: 0.8853\n",
      "  Val_Loss: 0.5305 | Val_Acc: 0.8266\n",
      "\n",
      "Epoch 20/30\n",
      "  Train_Loss: 0.3196 | Train_Acc: 0.8920\n",
      "  Val_Loss: 0.5258 | Val_Acc: 0.8236\n",
      "\n",
      "Epoch 21/30\n",
      "  Train_Loss: 0.3010 | Train_Acc: 0.8976\n",
      "  Val_Loss: 0.4671 | Val_Acc: 0.8456\n",
      "\n",
      "Epoch 22/30\n",
      "  Train_Loss: 0.2802 | Train_Acc: 0.9036\n",
      "  Val_Loss: 0.6857 | Val_Acc: 0.8160\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.6857\n",
      "Epoch 23/30\n",
      "  Train_Loss: 0.2707 | Train_Acc: 0.9074\n",
      "  Val_Loss: 0.5566 | Val_Acc: 0.8304\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.5566\n",
      "Epoch 24/30\n",
      "  Train_Loss: 0.2543 | Train_Acc: 0.9135\n",
      "  Val_Loss: 0.5508 | Val_Acc: 0.8300\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.5508\n",
      "Epoch 25/30\n",
      "  Train_Loss: 0.2403 | Train_Acc: 0.9189\n",
      "  Val_Loss: 0.6109 | Val_Acc: 0.8204\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.6109\n",
      "Epoch 26/30\n",
      "  Train_Loss: 0.2343 | Train_Acc: 0.9187\n",
      "  Val_Loss: 0.6167 | Val_Acc: 0.8288\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.6167\n",
      "Epoch 27/30\n",
      "  Train_Loss: 0.2136 | Train_Acc: 0.9260\n",
      "  Val_Loss: 0.9146 | Val_Acc: 0.7602\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.9146\n",
      "Epoch 28/30\n",
      "  Train_Loss: 0.2063 | Train_Acc: 0.9295\n",
      "  Val_Loss: 0.5257 | Val_Acc: 0.8438\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.5257\n",
      "Epoch 29/30\n",
      "  Train_Loss: 0.1996 | Train_Acc: 0.9326\n",
      "  Val_Loss: 0.5831 | Val_Acc: 0.8340\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 0.4671 | current value= 0.5831\n",
      "🛑Early stopping due to high risk of OVERFITTING\n",
      "Epoch 29: val_loss is INCREASING for 8 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▄▁▄▅▆▆▆▆▇▇▇█▇▇████▇████▆██</td></tr><tr><td>val_loss</td><td>▆▅▄▄█▄▄▂▃▂▂▂▂▂▁▂▂▁▁▁▁▂▁▁▂▂▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>29</td></tr><tr><td>train_acc</td><td>0.93258</td></tr><tr><td>train_loss</td><td>0.19962</td></tr><tr><td>val_acc</td><td>0.834</td></tr><tr><td>val_loss</td><td>0.58309</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResidualCNN_6Blocks</strong> at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2dw0nydb' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN/runs/2dw0nydb</a><br> View project at: <a href='https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN' target=\"_blank\">https://wandb.ai/emile-agbedanu-none/SimpleCNN%20Vs%20ResCNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250805_110810-2dw0nydb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Depth values to test\n",
    "# depth_values = [2, 3, 6]\n",
    "# num_epochs = 30    \n",
    "\n",
    "# # List to store results\n",
    "# results = []\n",
    "\n",
    "# for depth in depth_values:\n",
    "#     print(f\"\\n=== Testing depth = {depth} ===\")\n",
    "\n",
    "#     # ----- Simple CNN -----\n",
    "#     cnn_model = VariableDepthCNN(\n",
    "#         num_layers=depth,\n",
    "#         num_classes=10,\n",
    "#         base_channels=32,\n",
    "#         dropout_rate=0.3,\n",
    "#         in_channels=3,\n",
    "#         padding=1\n",
    "#     ).to(device)\n",
    "\n",
    "#     cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     train_losses_cnn, val_losses_cnn, epochs_cnn = train_model(\n",
    "#         cnn_model,\n",
    "#         train_loader,\n",
    "#         val_loader,\n",
    "#         cnn_optimizer,\n",
    "#         criterion,\n",
    "#         num_epochs=30,\n",
    "#         device=device,\n",
    "#         patience=8,\n",
    "#         min_delta=0.001,\n",
    "#         delta_overfit=0.01,\n",
    "#         overfit_patience=8,\n",
    "#         wandb_project='SimpleCNN Vs ResCNN',\n",
    "#         wandb_run_name=f\"SimpleCNN_{depth}Layers\"\n",
    "#     )\n",
    "\n",
    "#     test_loss_cnn, test_acc_cnn, test_prec_cnn = evaluate(\n",
    "#         cnn_model, test_loader, criterion, device\n",
    "#     )\n",
    "\n",
    "#     results.append((\"SimpleCNN\", depth, epochs_cnn, test_loss_cnn, test_acc_cnn, test_prec_cnn))\n",
    "\n",
    "#     # ----- Residual CNN -----\n",
    "#     rescnn_model = VariableDepthResNet(\n",
    "#         num_blocks=depth,\n",
    "#         num_classes=10,\n",
    "#         base_channels=64,\n",
    "#         dropout_rate=0.3,\n",
    "#         in_channels=3,\n",
    "#         padding=1\n",
    "#     ).to(device)\n",
    "\n",
    "#     rescnn_optimizer = torch.optim.Adam(rescnn_model.parameters(), lr=0.001)\n",
    "\n",
    "#     train_losses_rescnn, val_losses_rescnn, epochs_rescnn = train_model(\n",
    "#         rescnn_model,\n",
    "#         train_loader,\n",
    "#         val_loader,\n",
    "#         rescnn_optimizer,\n",
    "#         criterion,\n",
    "#         num_epochs=30,\n",
    "#         device=device,\n",
    "#         patience=8,\n",
    "#         min_delta=0.001,\n",
    "#         delta_overfit=0.01,\n",
    "#         overfit_patience=8,\n",
    "#         wandb_project='SimpleCNN Vs ResCNN',\n",
    "#         wandb_run_name=f\"ResidualCNN_{depth}Blocks\"\n",
    "#     )\n",
    "\n",
    "#     test_loss_rescnn, test_acc_rescnn, test_prec_rescnn = evaluate(\n",
    "#         rescnn_model, test_loader, criterion, device\n",
    "#     )\n",
    "\n",
    "#     results.append((\"ResidualCNN\", depth, epochs_rescnn, test_loss_rescnn, test_acc_rescnn, test_prec_rescnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061db3b",
   "metadata": {},
   "source": [
    "<h3><span style=\"font-size:24px; font-weight:bold;\">SimpleCNN</span> <span style=\"font-size:36px; font-weight:bold;\">Vs</span> <span style=\"font-size:24px; font-weight:bold;\">ResidualCNN REPORT</span></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a32ed2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "\n",
      "Comparison SimpleCNN vs ResidualCNN on TEST SET\n",
      "------------------------------------------------------------------------------\n",
      "|Model              | Depth  | Epochs  | Loss       | Accuracy   | Precision |\n",
      "------------------------------------------------------------------------------\n",
      "|SimpleCNN          | 2      | 13      | 1.4563     | 0.6789     | 0.6816    |\n",
      "|ResidualCNN        | 2      | 30      | 0.6779     | 0.7691     | 0.7880    |\n",
      "|SimpleCNN          | 3      | 12      | 1.2307     | 0.7414     | 0.7444    |\n",
      "|ResidualCNN        | 3      | 30      | 0.6206     | 0.8048     | 0.8158    |\n",
      "|SimpleCNN          | 6      | 15      | 0.9892     | 0.8111     | 0.8121    |\n",
      "|ResidualCNN        | 6      | 29      | 0.5847     | 0.8367     | 0.8450    |\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 78)\n",
    "print(\"\\nComparison SimpleCNN vs ResidualCNN on TEST SET\")\n",
    "print(\"-\" * 78)\n",
    "print(f\"|{'Model':<18} | {'Depth':<6} | {'Epochs':<7} | {'Loss':<10} | {'Accuracy':<10} | {'Precision':<10}|\")\n",
    "print(\"-\" * 78)\n",
    "\n",
    "for model_name, depth, epochs, loss, acc, prec in results:\n",
    "    print(f\"|{model_name:<18} | {depth:<6} | {epochs:<7} | {loss:<10.4f} | {acc:<10.4f} | {prec:<10.4f}|\")\n",
    "\n",
    "print(\"-\" * 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4de2f2-abc5-4f98-9eaf-3497f734a022",
   "metadata": {},
   "source": [
    "-----\n",
    "## Exercise 2: Choose at Least One\n",
    "\n",
    "Below are **three** exercises that ask you to deepen your understanding of Deep Networks for visual recognition. You must choose **at least one** of the below for your final submission -- feel free to do **more**, but at least **ONE** you must submit. Each exercise is designed to require you to dig your hands **deep** into the guts of your models in order to do new and interesting things.\n",
    "\n",
    "**Note**: These exercises are designed to use your small, custom CNNs and small datasets. This is to keep training times reasonable. If you have a decent GPU, feel free to use pretrained ResNets and larger datasets (e.g. the [Imagenette](https://pytorch.org/vision/0.20/generated/torchvision.datasets.Imagenette.html#torchvision.datasets.Imagenette) dataset at 160px)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07978e8e-9f2e-4949-9699-495af6cb6349",
   "metadata": {},
   "source": [
    "### Exercise 2.1: *Fine-tune* a pre-trained model\n",
    "Train one of your residual CNN models from Exercise 1.3 on CIFAR-10. Then:\n",
    "1. Use the pre-trained model as a **feature extractor** (i.e. to extract the feature activations of the layer input into the classifier) on CIFAR-100. Use a **classical** approach (e.g. Linear SVM, K-Nearest Neighbor, or Bayesian Generative Classifier) from scikit-learn to establish a **stable baseline** performance on CIFAR-100 using the features extracted using your CNN.\n",
    "2. Fine-tune your CNN on the CIFAR-100 training set and compare with your stable baseline. Experiment with different strategies:\n",
    "    - Unfreeze some of the earlier layers for fine-tuning.\n",
    "    - Test different optimizers (Adam, SGD, etc.).\n",
    "\n",
    "Each of these steps will require you to modify your model definition in some way. For 1, you will need to return the activations of the last fully-connected layer (or the global average pooling layer). For 2, you will need to replace the original, 10-class classifier with a new, randomly-initialized 100-class classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ecdf1",
   "metadata": {},
   "source": [
    "### **CIFAR-100 Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e81a3-08ca-4549-a2f8-f47cf5a0308b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:14<00:00, 12.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 128\n",
    "val_fraction = 0.1\n",
    "\n",
    "# Data transforms (same normalization stats as CIFAR-10)\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "def get_cifar100_loaders(batch_size=128, val_fraction=0.1, root='./data'):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    # Load full training set with train transforms\n",
    "    full_train_dataset = CIFAR100(root=root, train=True, download=True, transform=transform_train)\n",
    "    \n",
    "    # Compute lengths for train/val split\n",
    "    total_train = len(full_train_dataset)\n",
    "    val_size = int(total_train * val_fraction)\n",
    "    train_size = total_train - val_size\n",
    "    \n",
    "    # Split dataset\n",
    "    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Override val transform to test transforms (no augmentation)\n",
    "    val_dataset.dataset.transform = transform_test\n",
    "    \n",
    "    # Load test dataset with test transforms\n",
    "    test_dataset = CIFAR100(root=root, train=False, download=True, transform=transform_test)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Instantiate loaders\n",
    "train_loader_100, val_loader_100, test_loader_100 = get_cifar100_loaders(batch_size, val_fraction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee73f99",
   "metadata": {},
   "source": [
    " ### **Load Pre-trained ResidualCNN and Freeze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc3ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emile\\AppData\\Local\\Temp\\ipykernel_17088\\697541959.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ResCnn_model_100.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VariableDepthResNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (res_blocks): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_classes = 10         \n",
    "base_channels = 32       \n",
    "dropout_rate = 0.2\n",
    "in_channels = 3\n",
    "padding = 1  \n",
    "num_blocks=4  \n",
    "\n",
    "# Load the model from Exercise 1.3 (pre-trained on CIFAR-10)\n",
    "ResCnn_model_100 = VariableDepthResNet(\n",
    "    num_blocks, num_classes, base_channels, dropout_rate, in_channels, padding\n",
    ")\n",
    "\n",
    "# Load pre-trained weights\n",
    "ResCnn_model_100.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Freeze all layers\n",
    "for param in ResCnn_model_100.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "ResCnn_model_100.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e2160",
   "metadata": {},
   "source": [
    "### **Feature Extraction Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, data_loader, device):\n",
    "    model.to(device)\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Hook to capture features before the final FC layer\n",
    "    def hook_fn(module, input, output):\n",
    "        features_list.append(output.detach().cpu().numpy())\n",
    "\n",
    "    # Register hook on the layer before classifier\n",
    "    handle = model.fc.register_forward_hook(lambda m, i, o: features_list.append(o.detach().cpu().numpy()))\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)  # forward pass\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Remove hook\n",
    "    handle.remove()\n",
    "\n",
    "    # Concatenate all feature batches\n",
    "    features_array = np.concatenate(features_list, axis=0)\n",
    "    labels_array = np.array(all_labels)\n",
    "    return features_array, labels_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a71f2c",
   "metadata": {},
   "source": [
    "### **Baseline with classical SVM and KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c66e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline accuracy: 0.1519\n",
      "KNN baseline accuracy: 0.0811\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Extract features for train and test\n",
    "train_feats, train_labels = extract_features(ResCnn_model_100, train_loader_100, device)\n",
    "test_feats, test_labels = extract_features(ResCnn_model_100, test_loader_100, device)\n",
    "\n",
    "# Example 1: Linear SVM\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(train_feats, train_labels)\n",
    "svm_acc = accuracy_score(test_labels, svm_clf.predict(test_feats))\n",
    "print(f\"SVM baseline accuracy: {svm_acc:.4f}\")\n",
    "\n",
    "# Example 2: KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(train_feats, train_labels)\n",
    "knn_acc = accuracy_score(test_labels, knn_clf.predict(test_feats))\n",
    "print(f\"KNN baseline accuracy: {knn_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a34057",
   "metadata": {},
   "source": [
    "### **Fine-tuning and traning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d1834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Epoch 1/20\n",
      "  Train_Loss: 4.0348 | Train_Acc: 0.0784\n",
      "  Val_Loss: 3.4220 | Val_Acc: 0.1620\n",
      "\n",
      "Epoch 2/20\n",
      "  Train_Loss: 3.3929 | Train_Acc: 0.1574\n",
      "  Val_Loss: 3.1988 | Val_Acc: 0.1914\n",
      "\n",
      "Epoch 3/20\n",
      "  Train_Loss: 3.1494 | Train_Acc: 0.1963\n",
      "  Val_Loss: 2.8664 | Val_Acc: 0.2580\n",
      "\n",
      "Epoch 4/20\n",
      "  Train_Loss: 3.0139 | Train_Acc: 0.2222\n",
      "  Val_Loss: 2.8443 | Val_Acc: 0.2576\n",
      "\n",
      "Epoch 5/20\n",
      "  Train_Loss: 2.9290 | Train_Acc: 0.2378\n",
      "  Val_Loss: 2.7152 | Val_Acc: 0.2882\n",
      "\n",
      "Epoch 6/20\n",
      "  Train_Loss: 2.8612 | Train_Acc: 0.2574\n",
      "  Val_Loss: 2.6752 | Val_Acc: 0.2951\n",
      "\n",
      "Epoch 7/20\n",
      "  Train_Loss: 2.8071 | Train_Acc: 0.2624\n",
      "  Val_Loss: 2.7902 | Val_Acc: 0.2816\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 2.6752 | current value= 2.7902\n",
      "Epoch 8/20\n",
      "  Train_Loss: 2.7669 | Train_Acc: 0.2732\n",
      "  Val_Loss: 2.7101 | Val_Acc: 0.3029\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 2.6752 | current value= 2.7101\n",
      "Epoch 9/20\n",
      "  Train_Loss: 2.7280 | Train_Acc: 0.2810\n",
      "  Val_Loss: 2.5611 | Val_Acc: 0.3249\n",
      "\n",
      "Epoch 10/20\n",
      "  Train_Loss: 2.6999 | Train_Acc: 0.2883\n",
      "  Val_Loss: 2.4913 | Val_Acc: 0.3388\n",
      "\n",
      "Epoch 11/20\n",
      "  Train_Loss: 2.6621 | Train_Acc: 0.2950\n",
      "  Val_Loss: 2.5210 | Val_Acc: 0.3353\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 2.4913 | current value= 2.5210\n",
      "Epoch 12/20\n",
      "  Train_Loss: 2.6432 | Train_Acc: 0.2997\n",
      "  Val_Loss: 2.4652 | Val_Acc: 0.3426\n",
      "\n",
      "Epoch 13/20\n",
      "  Train_Loss: 2.6206 | Train_Acc: 0.3074\n",
      "  Val_Loss: 2.4727 | Val_Acc: 0.3480\n",
      "\n",
      "Epoch 14/20\n",
      "  Train_Loss: 2.5895 | Train_Acc: 0.3084\n",
      "  Val_Loss: 2.6162 | Val_Acc: 0.3273\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 2.4652 | current value= 2.6162\n",
      "Epoch 15/20\n",
      "  Train_Loss: 2.5700 | Train_Acc: 0.3192\n",
      "  Val_Loss: 2.4790 | Val_Acc: 0.3416\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 2.4652 | current value= 2.4790\n",
      "Epoch 16/20\n",
      "  Train_Loss: 2.5570 | Train_Acc: 0.3195\n",
      "  Val_Loss: 2.3892 | Val_Acc: 0.3602\n",
      "\n",
      "Epoch 17/20\n",
      "  Train_Loss: 2.5442 | Train_Acc: 0.3209\n",
      "  Val_Loss: 2.3571 | Val_Acc: 0.3757\n",
      "\n",
      "Epoch 18/20\n",
      "  Train_Loss: 2.5241 | Train_Acc: 0.3264\n",
      "  Val_Loss: 2.4066 | Val_Acc: 0.3569\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 2.3571 | current value= 2.4066\n",
      "Epoch 19/20\n",
      "  Train_Loss: 2.5076 | Train_Acc: 0.3270\n",
      "  Val_Loss: 2.4058 | Val_Acc: 0.3660\n",
      "\n",
      "⚠️WARNING:Change in the trend of value  val_loss: best value= 2.3571 | current value= 2.4058\n",
      "⚠️Δ(val_loss) < 0.001 for 1 consecutive epoch(s)\n",
      "Epoch 20/20\n",
      "  Train_Loss: 2.4941 | Train_Acc: 0.3313\n",
      "  Val_Loss: 2.2825 | Val_Acc: 0.3845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Modify classifier to output 100 classes\n",
    "ResCnn_model.fc = nn.Linear(ResCnn_model.fc.in_features, 100)\n",
    "\n",
    "# Unfreeze some earlier layers if desired (example: last residual block)\n",
    "for name, param in ResCnn_model.named_parameters():\n",
    "    if \"res_blocks\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "ResCnn_model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, ResCnn_model.parameters()), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "train_losses_ft, val_losses_ft, epochs_ft = train_model(\n",
    "    ResCnn_model,\n",
    "    train_loader_100,\n",
    "    val_loader_100,  \n",
    "    optimizer,\n",
    "    criterion,\n",
    "    num_epochs=50,\n",
    "    device=device,\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    delta_overfit=0.01,\n",
    "    overfit_patience=5,\n",
    "    wandb_project=\"Fine-tuning_model\", wandb_run_name=\"ResCNN_on_CIFAR100\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c13331d",
   "metadata": {},
   "source": [
    "### **Fine-tuned Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd922db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline SVM: 0.1519\n",
      "Baseline KNN: 0.0811\n",
      "Fine-tuned model accuracy: 0.3845\n"
     ]
    }
   ],
   "source": [
    "test_loss_ft, test_acc_ft, test_prec_ft = evaluate(\n",
    "    ResCnn_model,\n",
    "    test_loader_100,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "print(\"Baseline SVM:\", svm_acc)\n",
    "print(\"Baseline KNN:\", knn_acc)\n",
    "print(\"Fine-tuned model accuracy:\", test_acc_ft)\n",
    "\n",
    "\n",
    "# Comparison plot: KNN, SVM, Fine-tuned CNN\n",
    "model_names = [\"KNN (feature extractor)\", \"SVM (feature extractor)\", \"Fine-tuned CNN\"]\n",
    "accuracies = [knn_acc, svm_acc, test_acc_ft]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(model_names, accuracies, color=[\"gold\", \"darkorange\", \"mediumslateblue\"]) \n",
    "\n",
    "# Set y-axis limits between 0 and 1\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Label for the y-axis\n",
    "plt.ylabel(\"Accuracy on CIFAR-100\")\n",
    "\n",
    "# Title of the plot\n",
    "plt.title(\"Comparison: Classical Classifiers vs Fine-Tuning\")\n",
    "\n",
    "# Show horizontal grid lines\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
